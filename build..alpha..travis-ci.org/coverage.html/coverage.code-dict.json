{"/home/travis/build/npmtest/node-npmtest-ipfs/test.js":"/* istanbul instrument in package npmtest_ipfs */\n/*jslint\n    bitwise: true,\n    browser: true,\n    maxerr: 8,\n    maxlen: 96,\n    node: true,\n    nomen: true,\n    regexp: true,\n    stupid: true\n*/\n(function () {\n    'use strict';\n    var local;\n\n\n\n    // run shared js-env code - pre-init\n    (function () {\n        // init local\n        local = {};\n        // init modeJs\n        local.modeJs = (function () {\n            try {\n                return typeof navigator.userAgent === 'string' &&\n                    typeof document.querySelector('body') === 'object' &&\n                    typeof XMLHttpRequest.prototype.open === 'function' &&\n                    'browser';\n            } catch (errorCaughtBrowser) {\n                return module.exports &&\n                    typeof process.versions.node === 'string' &&\n                    typeof require('http').createServer === 'function' &&\n                    'node';\n            }\n        }());\n        // init global\n        local.global = local.modeJs === 'browser'\n            ? window\n            : global;\n        switch (local.modeJs) {\n        // re-init local from window.local\n        case 'browser':\n            local = local.global.utility2.objectSetDefault(\n                local.global.utility2_rollup || local.global.local,\n                local.global.utility2\n            );\n            break;\n        // re-init local from example.js\n        case 'node':\n            local = (local.global.utility2_rollup || require('utility2'))\n                .requireReadme();\n            break;\n        }\n        // export local\n        local.global.local = local;\n    }());\n\n\n\n    // run shared js-env code - function\n    (function () {\n        return;\n    }());\n    switch (local.modeJs) {\n\n\n\n    // run browser js-env code - function\n    case 'browser':\n        break;\n\n\n\n    // run node js-env code - function\n    case 'node':\n        break;\n    }\n\n\n\n    // run shared js-env code - post-init\n    (function () {\n        return;\n    }());\n    switch (local.modeJs) {\n\n\n\n    // run browser js-env code - post-init\n    case 'browser':\n        local.testCase_browser_nullCase = local.testCase_browser_nullCase || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test browsers's null-case handling-behavior-behavior\n         */\n            onError(null, options);\n        };\n\n        // run tests\n        local.nop(local.modeTest &&\n            document.querySelector('#testRunButton1') &&\n            document.querySelector('#testRunButton1').click());\n        break;\n\n\n\n    // run node js-env code - post-init\n    /* istanbul ignore next */\n    case 'node':\n        local.testCase_buildApidoc_default = local.testCase_buildApidoc_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildApidoc's default handling-behavior-behavior\n         */\n            options = { modulePathList: module.paths };\n            local.buildApidoc(options, onError);\n        };\n\n        local.testCase_buildApp_default = local.testCase_buildApp_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildApp's default handling-behavior-behavior\n         */\n            local.testCase_buildReadme_default(options, local.onErrorThrow);\n            local.testCase_buildLib_default(options, local.onErrorThrow);\n            local.testCase_buildTest_default(options, local.onErrorThrow);\n            local.testCase_buildCustomOrg_default(options, local.onErrorThrow);\n            options = [];\n            local.buildApp(options, onError);\n        };\n\n        local.testCase_buildCustomOrg_default = local.testCase_buildCustomOrg_default ||\n            function (options, onError) {\n            /*\n             * this function will test buildCustomOrg's default handling-behavior\n             */\n                options = {};\n                local.buildCustomOrg(options, onError);\n            };\n\n        local.testCase_buildLib_default = local.testCase_buildLib_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildLib's default handling-behavior\n         */\n            options = {};\n            local.buildLib(options, onError);\n        };\n\n        local.testCase_buildReadme_default = local.testCase_buildReadme_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildReadme's default handling-behavior-behavior\n         */\n            options = {};\n            local.buildReadme(options, onError);\n        };\n\n        local.testCase_buildTest_default = local.testCase_buildTest_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildTest's default handling-behavior\n         */\n            options = {};\n            local.buildTest(options, onError);\n        };\n\n        local.testCase_webpage_default = local.testCase_webpage_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test webpage's default handling-behavior\n         */\n            options = { modeCoverageMerge: true, url: local.serverLocalHost + '?modeTest=1' };\n            local.browserTest(options, onError);\n        };\n\n        // run test-server\n        local.testRunServer(local);\n        break;\n    }\n}());\n","/home/travis/build/npmtest/node-npmtest-ipfs/lib.npmtest_ipfs.js":"/* istanbul instrument in package npmtest_ipfs */\n/*jslint\n    bitwise: true,\n    browser: true,\n    maxerr: 8,\n    maxlen: 96,\n    node: true,\n    nomen: true,\n    regexp: true,\n    stupid: true\n*/\n(function () {\n    'use strict';\n    var local;\n\n\n\n    // run shared js-env code - pre-init\n    (function () {\n        // init local\n        local = {};\n        // init modeJs\n        local.modeJs = (function () {\n            try {\n                return typeof navigator.userAgent === 'string' &&\n                    typeof document.querySelector('body') === 'object' &&\n                    typeof XMLHttpRequest.prototype.open === 'function' &&\n                    'browser';\n            } catch (errorCaughtBrowser) {\n                return module.exports &&\n                    typeof process.versions.node === 'string' &&\n                    typeof require('http').createServer === 'function' &&\n                    'node';\n            }\n        }());\n        // init global\n        local.global = local.modeJs === 'browser'\n            ? window\n            : global;\n        // init utility2_rollup\n        local = local.global.utility2_rollup || local;\n        // init lib\n        local.local = local.npmtest_ipfs = local;\n        // init exports\n        if (local.modeJs === 'browser') {\n            local.global.utility2_npmtest_ipfs = local;\n        } else {\n            module.exports = local;\n            module.exports.__dirname = __dirname;\n            module.exports.module = module;\n        }\n    }());\n}());\n","/home/travis/build/npmtest/node-npmtest-ipfs/example.js":"/*\nexample.js\n\nquickstart example\n\ninstruction\n    1. save this script as example.js\n    2. run the shell command:\n        $ npm install npmtest-ipfs && PORT=8081 node example.js\n    3. play with the browser-demo on http://127.0.0.1:8081\n*/\n\n\n\n/* istanbul instrument in package npmtest_ipfs */\n/*jslint\n    bitwise: true,\n    browser: true,\n    maxerr: 8,\n    maxlen: 96,\n    node: true,\n    nomen: true,\n    regexp: true,\n    stupid: true\n*/\n(function () {\n    'use strict';\n    var local;\n\n\n\n    // run shared js-env code - pre-init\n    (function () {\n        // init local\n        local = {};\n        // init modeJs\n        local.modeJs = (function () {\n            try {\n                return typeof navigator.userAgent === 'string' &&\n                    typeof document.querySelector('body') === 'object' &&\n                    typeof XMLHttpRequest.prototype.open === 'function' &&\n                    'browser';\n            } catch (errorCaughtBrowser) {\n                return module.exports &&\n                    typeof process.versions.node === 'string' &&\n                    typeof require('http').createServer === 'function' &&\n                    'node';\n            }\n        }());\n        // init global\n        local.global = local.modeJs === 'browser'\n            ? window\n            : global;\n        // init utility2_rollup\n        local = local.global.utility2_rollup || (local.modeJs === 'browser'\n            ? local.global.utility2_npmtest_ipfs\n            : global.utility2_moduleExports);\n        // export local\n        local.global.local = local;\n    }());\n    switch (local.modeJs) {\n\n\n\n    // post-init\n    // run browser js-env code - post-init\n    /* istanbul ignore next */\n    case 'browser':\n        local.testRunBrowser = function (event) {\n            if (!event || (event &&\n                    event.currentTarget &&\n                    event.currentTarget.className &&\n                    event.currentTarget.className.includes &&\n                    event.currentTarget.className.includes('onreset'))) {\n                // reset output\n                Array.from(\n                    document.querySelectorAll('body > .resettable')\n                ).forEach(function (element) {\n                    switch (element.tagName) {\n                    case 'INPUT':\n                    case 'TEXTAREA':\n                        element.value = '';\n                        break;\n                    default:\n                        element.textContent = '';\n                    }\n                });\n            }\n            switch (event && event.currentTarget && event.currentTarget.id) {\n            case 'testRunButton1':\n                // show tests\n                if (document.querySelector('#testReportDiv1').style.display === 'none') {\n                    document.querySelector('#testReportDiv1').style.display = 'block';\n                    document.querySelector('#testRunButton1').textContent =\n                        'hide internal test';\n                    local.modeTest = true;\n                    local.testRunDefault(local);\n                // hide tests\n                } else {\n                    document.querySelector('#testReportDiv1').style.display = 'none';\n                    document.querySelector('#testRunButton1').textContent = 'run internal test';\n                }\n                break;\n            // custom-case\n            default:\n                break;\n            }\n            if (document.querySelector('#inputTextareaEval1') && (!event || (event &&\n                    event.currentTarget &&\n                    event.currentTarget.className &&\n                    event.currentTarget.className.includes &&\n                    event.currentTarget.className.includes('oneval')))) {\n                // try to eval input-code\n                try {\n                    /*jslint evil: true*/\n                    eval(document.querySelector('#inputTextareaEval1').value);\n                } catch (errorCaught) {\n                    console.error(errorCaught);\n                }\n            }\n        };\n        // log stderr and stdout to #outputTextareaStdout1\n        ['error', 'log'].forEach(function (key) {\n            console[key + '_original'] = console[key];\n            console[key] = function () {\n                var element;\n                console[key + '_original'].apply(console, arguments);\n                element = document.querySelector('#outputTextareaStdout1');\n                if (!element) {\n                    return;\n                }\n                // append text to #outputTextareaStdout1\n                element.value += Array.from(arguments).map(function (arg) {\n                    return typeof arg === 'string'\n                        ? arg\n                        : JSON.stringify(arg, null, 4);\n                }).join(' ') + '\\n';\n                // scroll textarea to bottom\n                element.scrollTop = element.scrollHeight;\n            };\n        });\n        // init event-handling\n        ['change', 'click', 'keyup'].forEach(function (event) {\n            Array.from(document.querySelectorAll('.on' + event)).forEach(function (element) {\n                element.addEventListener(event, local.testRunBrowser);\n            });\n        });\n        // run tests\n        local.testRunBrowser();\n        break;\n\n\n\n    // run node js-env code - post-init\n    /* istanbul ignore next */\n    case 'node':\n        // export local\n        module.exports = local;\n        // require modules\n        local.fs = require('fs');\n        local.http = require('http');\n        local.url = require('url');\n        // init assets\n        local.assetsDict = local.assetsDict || {};\n        /* jslint-ignore-begin */\n        local.assetsDict['/assets.index.template.html'] = '\\\n<!doctype html>\\n\\\n<html lang=\"en\">\\n\\\n<head>\\n\\\n<meta charset=\"UTF-8\">\\n\\\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\\n\\\n<title>{{env.npm_package_name}} (v{{env.npm_package_version}})</title>\\n\\\n<style>\\n\\\n/*csslint\\n\\\n    box-sizing: false,\\n\\\n    universal-selector: false\\n\\\n*/\\n\\\n* {\\n\\\n    box-sizing: border-box;\\n\\\n}\\n\\\nbody {\\n\\\n    background: #dde;\\n\\\n    font-family: Arial, Helvetica, sans-serif;\\n\\\n    margin: 2rem;\\n\\\n}\\n\\\nbody > * {\\n\\\n    margin-bottom: 1rem;\\n\\\n}\\n\\\n.utility2FooterDiv {\\n\\\n    margin-top: 20px;\\n\\\n    text-align: center;\\n\\\n}\\n\\\n</style>\\n\\\n<style>\\n\\\n/*csslint\\n\\\n*/\\n\\\ntextarea {\\n\\\n    font-family: monospace;\\n\\\n    height: 10rem;\\n\\\n    width: 100%;\\n\\\n}\\n\\\ntextarea[readonly] {\\n\\\n    background: #ddd;\\n\\\n}\\n\\\n</style>\\n\\\n</head>\\n\\\n<body>\\n\\\n<!-- utility2-comment\\n\\\n<div id=\"ajaxProgressDiv1\" style=\"background: #d00; height: 2px; left: 0; margin: 0; padding: 0; position: fixed; top: 0; transition: background 0.5s, width 1.5s; width: 25%;\"></div>\\n\\\nutility2-comment -->\\n\\\n<h1>\\n\\\n<!-- utility2-comment\\n\\\n    <a\\n\\\n        {{#if env.npm_package_homepage}}\\n\\\n        href=\"{{env.npm_package_homepage}}\"\\n\\\n        {{/if env.npm_package_homepage}}\\n\\\n        target=\"_blank\"\\n\\\n    >\\n\\\nutility2-comment -->\\n\\\n        {{env.npm_package_name}} (v{{env.npm_package_version}})\\n\\\n<!-- utility2-comment\\n\\\n    </a>\\n\\\nutility2-comment -->\\n\\\n</h1>\\n\\\n<h3>{{env.npm_package_description}}</h3>\\n\\\n<!-- utility2-comment\\n\\\n<h4><a download href=\"assets.app.js\">download standalone app</a></h4>\\n\\\n<button class=\"onclick onreset\" id=\"testRunButton1\">run internal test</button><br>\\n\\\n<div id=\"testReportDiv1\" style=\"display: none;\"></div>\\n\\\nutility2-comment -->\\n\\\n\\n\\\n\\n\\\n\\n\\\n<label>stderr and stdout</label>\\n\\\n<textarea class=\"resettable\" id=\"outputTextareaStdout1\" readonly></textarea>\\n\\\n<!-- utility2-comment\\n\\\n{{#if isRollup}}\\n\\\n<script src=\"assets.app.js\"></script>\\n\\\n{{#unless isRollup}}\\n\\\nutility2-comment -->\\n\\\n<script src=\"assets.utility2.rollup.js\"></script>\\n\\\n<script src=\"jsonp.utility2._stateInit?callback=window.utility2._stateInit\"></script>\\n\\\n<script src=\"assets.npmtest_ipfs.rollup.js\"></script>\\n\\\n<script src=\"assets.example.js\"></script>\\n\\\n<script src=\"assets.test.js\"></script>\\n\\\n<!-- utility2-comment\\n\\\n{{/if isRollup}}\\n\\\nutility2-comment -->\\n\\\n<div class=\"utility2FooterDiv\">\\n\\\n    [ this app was created with\\n\\\n    <a href=\"https://github.com/kaizhu256/node-utility2\" target=\"_blank\">utility2</a>\\n\\\n    ]\\n\\\n</div>\\n\\\n</body>\\n\\\n</html>\\n\\\n';\n        /* jslint-ignore-end */\n        if (local.templateRender) {\n            local.assetsDict['/'] = local.templateRender(\n                local.assetsDict['/assets.index.template.html'],\n                {\n                    env: local.objectSetDefault(local.env, {\n                        npm_package_description: 'the greatest app in the world!',\n                        npm_package_name: 'my-app',\n                        npm_package_nameAlias: 'my_app',\n                        npm_package_version: '0.0.1'\n                    })\n                }\n            );\n        } else {\n            local.assetsDict['/'] = local.assetsDict['/assets.index.template.html']\n                .replace((/\\{\\{env\\.(\\w+?)\\}\\}/g), function (match0, match1) {\n                    // jslint-hack\n                    String(match0);\n                    switch (match1) {\n                    case 'npm_package_description':\n                        return 'the greatest app in the world!';\n                    case 'npm_package_name':\n                        return 'my-app';\n                    case 'npm_package_nameAlias':\n                        return 'my_app';\n                    case 'npm_package_version':\n                        return '0.0.1';\n                    }\n                });\n        }\n        // run the cli\n        if (local.global.utility2_rollup || module !== require.main) {\n            break;\n        }\n        local.assetsDict['/assets.example.js'] =\n            local.assetsDict['/assets.example.js'] ||\n            local.fs.readFileSync(__filename, 'utf8');\n        // bug-workaround - long $npm_package_buildCustomOrg\n        /* jslint-ignore-begin */\n        local.assetsDict['/assets.npmtest_ipfs.rollup.js'] =\n            local.assetsDict['/assets.npmtest_ipfs.rollup.js'] ||\n            local.fs.readFileSync(\n                local.npmtest_ipfs.__dirname + '/lib.npmtest_ipfs.js',\n                'utf8'\n            ).replace((/^#!/), '//');\n        /* jslint-ignore-end */\n        local.assetsDict['/favicon.ico'] = local.assetsDict['/favicon.ico'] || '';\n        // if $npm_config_timeout_exit exists,\n        // then exit this process after $npm_config_timeout_exit ms\n        if (Number(process.env.npm_config_timeout_exit)) {\n            setTimeout(process.exit, Number(process.env.npm_config_timeout_exit));\n        }\n        // start server\n        if (local.global.utility2_serverHttp1) {\n            break;\n        }\n        process.env.PORT = process.env.PORT || '8081';\n        console.error('server starting on port ' + process.env.PORT);\n        local.http.createServer(function (request, response) {\n            request.urlParsed = local.url.parse(request.url);\n            if (local.assetsDict[request.urlParsed.pathname] !== undefined) {\n                response.end(local.assetsDict[request.urlParsed.pathname]);\n                return;\n            }\n            response.statusCode = 404;\n            response.end();\n        }).listen(process.env.PORT);\n        break;\n    }\n}());\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs/src/core/index.js":"'use strict'\n\nconst BlockService = require('ipfs-block-service')\nconst IPLDResolver = require('ipld-resolver')\nconst PeerId = require('peer-id')\nconst PeerInfo = require('peer-info')\nconst multiaddr = require('multiaddr')\nconst multihash = require('multihashes')\nconst PeerBook = require('peer-book')\nconst CID = require('cids')\nconst debug = require('debug')\nconst extend = require('deep-extend')\nconst EventEmitter = require('events')\n\nconst defaultRepo = require('./default-repo')\nconst boot = require('./boot')\nconst components = require('./components')\n\nclass IPFS extends EventEmitter {\n  constructor (options) {\n    super()\n\n    this._options = {\n      init: true,\n      start: true,\n      EXPERIMENTAL: {}\n    }\n\n    options = options || {}\n\n    extend(this._options, options)\n\n    if (options.init === false) {\n      this._options.init = false\n    }\n\n    if (!(options.start === false)) {\n      this._options.start = true\n    }\n\n    if (typeof options.repo === 'string' ||\n        options.repo === undefined) {\n      this._repo = defaultRepo(options.repo)\n    } else {\n      this._repo = options.repo\n    }\n\n    // IPFS utils\n    this.log = debug('jsipfs')\n    this.log.err = debug('jsipfs:err')\n\n    this.on('error', (err) => this.log(err))\n\n    // IPFS types\n    this.types = {\n      Buffer: Buffer,\n      PeerId: PeerId,\n      PeerInfo: PeerInfo,\n      multiaddr: multiaddr,\n      multihash: multihash,\n      CID: CID\n    }\n\n    // IPFS Core Internals\n    // this._repo - assigned above\n    this._peerInfoBook = new PeerBook()\n    this._peerInfo = undefined\n    this._libp2pNode = undefined\n    this._bitswap = undefined\n    this._blockService = new BlockService(this._repo)\n    this._ipldResolver = new IPLDResolver(this._blockService)\n    this._pubsub = undefined\n\n    // IPFS Core exposed components\n    //   - for booting up a node\n    this.init = components.init(this)\n    this.preStart = components.preStart(this)\n    this.start = components.start(this)\n    this.stop = components.stop(this)\n    this.isOnline = components.isOnline(this)\n    //   - interface-ipfs-core defined API\n    this.version = components.version(this)\n    this.id = components.id(this)\n    this.repo = components.repo(this)\n    this.bootstrap = components.bootstrap(this)\n    this.config = components.config(this)\n    this.block = components.block(this)\n    this.object = components.object(this)\n    this.dag = components.dag(this)\n    this.libp2p = components.libp2p(this)\n    this.swarm = components.swarm(this)\n    this.files = components.files(this)\n    this.bitswap = components.bitswap(this)\n    this.ping = components.ping(this)\n    this.pubsub = components.pubsub(this)\n\n    if (this._options.EXPERIMENTAL.pubsub) {\n      this.log('EXPERIMENTAL pubsub is enabled')\n    }\n    this.state = require('./state')(this)\n\n    boot(this)\n  }\n}\n\nexports = module.exports = IPFS\n\nexports.createNode = (options) => {\n  return new IPFS(options)\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs-block-service/src/index.js":"'use strict'\n\n/**\n * BlockService is a hybrid block datastore. It stores data in a local\n * datastore and may retrieve data from a remote Exchange.\n * It uses an internal `datastore.Datastore` instance to store values.\n */\nclass BlockService {\n  /**\n   * Create a new BlockService\n   *\n   * @param {IPFSRepo} ipfsRepo\n   * @returns {BlockService}\n   */\n  constructor (ipfsRepo) {\n    this._repo = ipfsRepo\n    this._bitswap = null\n  }\n\n  /**\n   * Add a bitswap instance that communicates with the\n   * network to retreive blocks that are not in the local store.\n   *\n   * If the node is online all requests for blocks first\n   * check locally and afterwards ask the network for the blocks.\n   *\n   * @param {Bitswap} bitswap\n   * @returns {void}\n   */\n  goOnline (bitswap) {\n    this._bitswap = bitswap\n  }\n\n  /**\n   * Go offline, i.e. drop the reference to bitswap.\n   *\n   * @returns {void}\n   */\n  goOffline () {\n    this._bitswap = null\n  }\n\n  /**\n   * Is the blockservice online, i.e. is bitswap present.\n   *\n   * @returns {bool}\n   */\n  isOnline () {\n    return this._bitswap != null\n  }\n\n  /**\n   * Put a block to the underlying datastore.\n   *\n   * @param {Block} block\n   * @param {function(Error)} callback\n   * @returns {void}\n   */\n  put (block, callback) {\n    if (this.isOnline()) {\n      return this._bitswap.put(block, callback)\n    }\n\n    this._repo.blockstore.put(block, callback)\n  }\n\n  /**\n   * Put a multiple blocks to the underlying datastore.\n   *\n   * @param {Array<Block>} blocks\n   * @param {function(Error)} callback\n   * @returns {void}\n   */\n  putMany (blocks, callback) {\n    if (this.isOnline()) {\n      return this._bitswap.putMany(blocks, callback)\n    }\n\n    this._repo.blockstore.putMany(blocks, callback)\n  }\n\n  /**\n   * Get a block by cid.\n   *\n   * @param {CID} cid\n   * @param {function(Error, Block)} callback\n   * @returns {void}\n   */\n  get (cid, callback) {\n    if (this.isOnline()) {\n      return this._bitswap.get(cid, callback)\n    }\n\n    return this._repo.blockstore.get(cid, callback)\n  }\n\n  /**\n   * Delete a block from the blockstore.\n   *\n   * @param {CID} cid\n   * @param {function(Error)} callback\n   * @return {void}\n   */\n  delete (cid, callback) {\n    this._repo.blockstore.delete(cid, callback)\n  }\n}\n\nmodule.exports = BlockService\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs-block/src/index.js":"'use strict'\n\nconst CID = require('cids')\n\n/**\n * Represents an immutable block of data that is uniquely referenced with a cid.\n *\n * @constructor\n * @param {Buffer} data - The data to be stored in the block as a buffer.\n * @param {CID} cid - The cid of the data\n *\n * @example\n * const block = new Block(new Buffer('a012d83b20f9371...'))\n */\nclass Block {\n  constructor (data, cid) {\n    if (!data || !Buffer.isBuffer(data)) {\n      throw new Error('first argument  must be a buffer')\n    }\n\n    if (!cid || !CID.isCID(cid)) {\n      throw new Error('second argument must be a CID')\n    }\n\n    this._data = data\n    this._cid = cid\n  }\n\n  /**\n   * The data of this block.\n   *\n   * @type {Buffer}\n   */\n  get data () {\n    return this._data\n  }\n\n  set data (val) {\n    throw new Error('Tried to change an immutable block')\n  }\n\n  /**\n   * The cid of the data this block represents.\n   *\n   * @type {CID}\n   */\n  get cid () {\n    return this._cid\n  }\n\n  set cid (val) {\n    throw new Error('Tried to change an immutable block')\n  }\n\n  /**\n   * Check if the given value is a Block.\n   *\n   * @param {any} other\n   * @returns {bool}\n   */\n  static isBlock (other) {\n    return other && other.constructor.name === 'Block'\n  }\n}\n\nmodule.exports = Block\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs/src/core/default-repo.js":"'use strict'\n\nconst os = require('os')\nconst IPFSRepo = require('ipfs-repo')\nconst path = require('path')\n\nmodule.exports = (dir) => {\n  const repoPath = dir || path.join(os.homedir(), '.jsipfs')\n\n  return new IPFSRepo(repoPath)\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs-repo/src/index.js":"'use strict'\n\nconst core = require('datastore-core')\nconst MountStore = core.MountDatastore\nconst ShardingStore = core.ShardingDatastore\n\nconst Key = require('interface-datastore').Key\nconst LevelStore = require('datastore-level')\nconst waterfall = require('async/waterfall')\nconst series = require('async/series')\nconst parallel = require('async/parallel')\nconst Multiaddr = require('multiaddr')\nconst Buffer = require('safe-buffer').Buffer\nconst assert = require('assert')\nconst path = require('path')\nconst debug = require('debug')\n\nconst version = require('./version')\nconst config = require('./config')\nconst blockstore = require('./blockstore')\n\nconst log = debug('repo')\n\nconst apiFile = new Key('api')\nconst flatfsDirectory = 'blocks'\nconst levelDirectory = 'datastore'\nconst repoVersion = 5\n\n/**\n * IpfsRepo implements all required functionality to read and write to an ipfs repo.\n *\n */\nclass IpfsRepo {\n  /**\n   * @param {string} repoPath - path where the repo is stored\n   * @param {object} options - Configuration\n   * @param {Datastore} options.fs\n   * @param {Leveldown} options.level\n   * @param {object} [options.fsOptions={}]\n   * @param {bool} [options.sharding=true] - Enable sharding (flatfs on disk), not needed in the browser.\n   * @param {string} [options.lock='fs'] - Either `fs` or `memory`.\n   */\n  constructor (repoPath, options) {\n    assert.equal(typeof repoPath, 'string', 'missing repoPath')\n\n    if (options == null) {\n      options = require('./default-options')\n    }\n\n    this.closed = true\n    this.path = repoPath\n    this.options = Object.assign({\n      sharding: true,\n      lock: 'fs'\n    }, options)\n    this._fsOptions = Object.assign({}, options.fsOptions)\n    const FsStore = this.options.fs\n    this._fsStore = new FsStore(this.path, Object.assign({}, this._fsOptions, {\n      extension: ''\n    }))\n\n    this.version = version(this._fsStore)\n    this.config = config(this._fsStore)\n\n    if (this.options.lock === 'memory') {\n      this._locker = require('./lock-memory')\n    } else if (this.options.lock === 'fs') {\n      this._locker = require('./lock')\n    } else {\n      throw new Error('Unkown lock options: ' + this.options.lock)\n    }\n  }\n\n  /**\n   * Initialize a new repo.\n   *\n   * @param {Object} config - config to write into `config`.\n   * @param {function(Error)} callback\n   * @returns {void}\n   */\n  init (config, callback) {\n    log('initializing at: %s', this.path)\n\n    series([\n      (cb) => this._fsStore.open((err) => {\n        if (err && err.message === 'Already open') {\n          return cb()\n        }\n        cb(err)\n      }),\n      (cb) => this.config.set(config, cb),\n      (cb) => this.version.set(repoVersion, cb)\n    ], callback)\n  }\n\n  /**\n   * Open the repo. If the repo is already open no action will be taken.\n   * If the repo is not initialized it will return an error.\n   *\n   * @param {function(Error)} callback\n   * @returns {void}\n   */\n  open (callback) {\n    if (!this.closed) {\n      return callback(new Error('repo is already open'))\n    }\n    log('opening at: %s', this.path)\n\n    // check if the repo is already initialized\n    waterfall([\n      (cb) => this._fsStore.open((err) => {\n        if (err && err.message === 'Already open') {\n          return cb()\n        }\n        cb(err)\n      }),\n      (cb) => this._isInitialized(cb),\n      (cb) => this._locker.lock(this.path, cb),\n      (lck, cb) => {\n        log('aquired repo.lock')\n        this.lockfile = lck\n\n        log('creating flatfs')\n        const FsStore = this.options.fs\n        const s = new FsStore(path.join(this.path, flatfsDirectory), this._fsOptions)\n\n        if (this.options.sharding) {\n          const shard = new core.shard.NextToLast(2)\n          ShardingStore.createOrOpen(s, shard, cb)\n        } else {\n          cb(null, s)\n        }\n      },\n      (flatfs, cb) => {\n        log('Flatfs store opened')\n        this.store = new MountStore([{\n          prefix: new Key(flatfsDirectory),\n          datastore: flatfs\n        }, {\n          prefix: new Key('/'),\n          datastore: new LevelStore(path.join(this.path, levelDirectory), {\n            db: this.options.level\n          })\n        }])\n\n        this.blockstore = blockstore(this)\n        this.closed = false\n        cb()\n      }\n    ], (err) => {\n      if (err && this.lockfile) {\n        return this.lockfile.close((err2) => {\n          log('error removing lock', err2)\n          callback(err)\n        })\n      }\n\n      callback(err)\n    })\n  }\n\n  /**\n   * Check if the repo is already initialized.\n   *\n   * @private\n   * @param {function(Error)} callback\n   * @returns {void}\n   */\n  _isInitialized (callback) {\n    log('init check')\n    parallel([\n      (cb) => this.config.exists(cb),\n      (cb) => this.version.check(repoVersion, cb)\n    ], (err, res) => {\n      log('init', err, res)\n      if (err) {\n        return callback(err)\n      }\n\n      if (!res[0]) {\n        return callback(new Error('repo is not initialized yet'))\n      }\n      callback()\n    })\n  }\n\n  /**\n   * Close the repo and cleanup.\n   *\n   * @param {function(Error)} callback\n   * @returns {void}\n   */\n  close (callback) {\n    if (this.closed) {\n      return callback(new Error('repo is already closed'))\n    }\n\n    log('closing at: %s', this.path)\n    series([\n      (cb) => this._fsStore.delete(apiFile, (err) => {\n        if (err && err.message.startsWith('ENOENT')) {\n          return cb()\n        }\n        cb(err)\n      }),\n      (cb) => this.store.close(cb),\n      (cb) => this._fsStore.close(cb),\n      (cb) => {\n        log('unlocking')\n        this.closed = true\n        this.lockfile.close(cb)\n      },\n      (cb) => {\n        this.lockfile = null\n        cb()\n      }\n    ], (err) => callback(err))\n  }\n\n  /**\n   * Check if a repo exists.\n   *\n   * @param {function(Error, bool)} callback\n   * @returns {void}\n   */\n  exists (callback) {\n    this.version.exists(callback)\n  }\n\n  /**\n   * Set the api address, by writing it to the `/api` file.\n   *\n   * @param {Multiaddr} addr\n   * @param {function(Error)} callback\n   * @returns {void}\n   */\n  setApiAddress (addr, callback) {\n    this._fsStore.put(apiFile, Buffer.from(addr.toString()), callback)\n  }\n\n  /**\n   * Returns the registered API address, according to the `/api` file in this respo.\n   *\n   * @param {function(Error, Mulitaddr)} callback\n   * @returns {void}\n   */\n  apiAddress (callback) {\n    this._fsStore.get(apiFile, (err, rawAddr) => {\n      if (err) {\n        return callback(err)\n      }\n\n      callback(null, new Multiaddr(rawAddr.toString()))\n    })\n  }\n}\n\nmodule.exports = IpfsRepo\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs-repo/src/version.js":"'use strict'\n\nconst Key = require('interface-datastore').Key\nconst debug = require('debug')\nconst log = debug('repo:version')\n\nconst versionKey = new Key('version')\n\nmodule.exports = (store) => {\n  return {\n    /**\n     * Check if a version file exists.\n     *\n     * @param {function(Error, bool)} callback\n     * @returns {void}\n     */\n    exists (callback) {\n      store.has(versionKey, callback)\n    },\n    /**\n     * Get the current version.\n     *\n     * @param {function(Error, number)} callback\n     * @returns {void}\n     */\n    get (callback) {\n      store.get(versionKey, (err, buf) => {\n        if (err) {\n          return callback(err)\n        }\n        callback(null, parseInt(buf.toString().trim(), 10))\n      })\n    },\n    /**\n     * Set the version of the repo, writing it to the underlying store.\n     *\n     * @param {number} version\n     * @param {function(Error)} callback\n     * @returns {void}\n     */\n    set (version, callback) {\n      store.put(versionKey, new Buffer(String(version)), callback)\n    },\n    /**\n     * Check the current version, and return an error on missmatch\n     * @param {number} expected\n     * @param {function(Error)} callback\n     * @returns {void}\n     */\n    check (expected, callback) {\n      this.get((err, version) => {\n        if (err) {\n          return callback(err)\n        }\n        log('comparing version: %s and %s', version, expected)\n        if (version !== expected) {\n          return callback(new Error(`version mismatch: expected v${expected}, found v${version}`))\n        }\n        callback()\n      })\n    }\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs-repo/src/config.js":"'use strict'\n\nconst Key = require('interface-datastore').Key\n\nconst configKey = new Key('config')\n\nmodule.exports = (store) => {\n  return {\n    /**\n     * Get the current configuration from the repo.\n     *\n     * @param {function(Error, Object)} callback\n     * @returns {void}\n     */\n    get (callback) {\n      store.get(configKey, (err, value) => {\n        if (err) {\n          return callback(err)\n        }\n\n        let config\n        try {\n          config = JSON.parse(value.toString())\n        } catch (err) {\n          return callback(err)\n        }\n        callback(null, config)\n      })\n    },\n    /**\n     * Set the current configuration for this repo.\n     *\n     * @param {Object} config - the config object to be written\n     * @param {function(Error)} callback\n     * @returns {void}\n     */\n    set (config, callback) {\n      const buf = new Buffer(JSON.stringify(config, null, 2))\n\n      store.put(configKey, buf, callback)\n    },\n    /**\n     * Check if a config file exists.\n     *\n     * @param {function(Error, bool)} callback\n     * @returns {void}\n     */\n    exists (callback) {\n      store.has(configKey, callback)\n    }\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs-repo/src/blockstore.js":"'use strict'\n\nconst NamespaceStore = require('datastore-core').NamespaceDatastore\nconst Key = require('interface-datastore').Key\nconst base32 = require('base32.js')\nconst Block = require('ipfs-block')\nconst setImmediate = require('async/setImmediate')\nconst reject = require('async/reject')\nconst CID = require('cids')\n\nconst blockPrefix = new Key('blocks')\n\n/**\n * Transform a raw buffer to a base32 encoded key.\n *\n * @param {Buffer} rawKey\n * @returns {Key}\n */\nconst keyFromBuffer = (rawKey) => {\n  const enc = new base32.Encoder()\n  return new Key('/' + enc.write(rawKey).finalize(), false)\n}\n\n/**\n * Transform a cid to the appropriate datastore key.\n *\n * @param {CID} cid\n * @returns {Key}\n */\nconst cidToDsKey = (cid) => {\n  return keyFromBuffer(cid.buffer)\n}\n\nmodule.exports = (repo) => {\n  const store = new NamespaceStore(repo.store, blockPrefix)\n  return {\n    /**\n     * Get a single block by CID.\n     *\n     * @param {CID} cid\n     * @param {function(Error, Block)} callback\n     * @returns {void}\n     */\n    get (cid, callback) {\n      if (!CID.isCID(cid)) {\n        return setImmediate(() => {\n          callback(new Error('Not a valid cid'))\n        })\n      }\n\n      const k = cidToDsKey(cid)\n      store.get(k, (err, blockData) => {\n        if (err) {\n          return callback(err)\n        }\n\n        callback(null, new Block(blockData, cid))\n      })\n    },\n    put (block, callback) {\n      if (!Block.isBlock(block)) {\n        return setImmediate(() => {\n          callback(new Error('invalid block'))\n        })\n      }\n\n      const k = cidToDsKey(block.cid)\n\n      store.has(k, (err, exists) => {\n        if (err) {\n          return callback(err)\n        }\n        if (exists) {\n          return callback()\n        }\n\n        store.put(k, block.data, callback)\n      })\n    },\n    /**\n     * Like put, but for more.\n     *\n     * @param {Array<Block>} blocks\n     * @param {function(Error)} callback\n     * @returns {void}\n     */\n    putMany (blocks, callback) {\n      const keys = blocks.map((b) => ({\n        key: cidToDsKey(b.cid),\n        block: b\n      }))\n\n      const batch = store.batch()\n      reject(keys, (k, cb) => store.has(k.key, cb), (err, newKeys) => {\n        if (err) {\n          return callback(err)\n        }\n\n        newKeys.forEach((k) => {\n          batch.put(k.key, k.block.data)\n        })\n\n        batch.commit(callback)\n      })\n    },\n    /**\n     * Does the store contain block with this cid?\n     *\n     * @param {CID} cid\n     * @param {function(Error, bool)} callback\n     * @returns {void}\n     */\n    has (cid, callback) {\n      if (!CID.isCID(cid)) {\n        return setImmediate(() => {\n          callback(new Error('Not a valid cid'))\n        })\n      }\n\n      store.has(cidToDsKey(cid), callback)\n    },\n    /**\n     * Delete a block from the store\n     *\n     * @param {CID} cid\n     * @param {function(Error)} callback\n     * @returns {void}\n     */\n    delete (cid, callback) {\n      if (!CID.isCID(cid)) {\n        return setImmediate(() => {\n          callback(new Error('Not a valid cid'))\n        })\n      }\n\n      store.delete(cidToDsKey(cid), callback)\n    }\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs/src/core/boot.js":"'use strict'\n\nconst waterfall = require('async/waterfall')\nconst series = require('async/series')\nconst extend = require('deep-extend')\n\n// Boot an IPFS node depending on the options set\nmodule.exports = (self) => {\n  self.log('booting')\n  const options = self._options\n  const doInit = options.init\n  const doStart = options.start\n  const config = options.config\n  const setConfig = config && typeof config === 'object'\n  const repoOpen = !self._repo.closed\n\n  const customInitOptions = typeof options.init === 'object' ? options.init : {}\n  const initOptions = Object.assign({\n    bits: 2048\n  }, customInitOptions)\n\n  // Checks if a repo exists, and if so opens it\n  // Will return callback with a bool indicating the existence\n  // of the repo\n  const maybeOpenRepo = (cb) => {\n    // nothing to do\n    if (repoOpen) {\n      return cb(null, true)\n    }\n\n    series([\n      (cb) => self._repo.open(cb),\n      (cb) => self.preStart(cb),\n      (cb) => {\n        self.state.initialized()\n        cb(null, true)\n      }\n    ], (err, res) => {\n      if (err) {\n        // If the error is that no repo exists,\n        // which happens when the version file is not found\n        // we just want to signal that no repo exist, not\n        // fail the whole process.\n        // TODO: improve datastore and ipfs-repo implemenations so this error is a bit more unified\n        if (err.message.match(/not found/) || // indexeddb\n            err.message.match(/ENOENT/) || // fs\n            err.message.match(/No value/) // memory\n           ) {\n          return cb(null, false)\n        }\n        return cb(err)\n      }\n      cb(null, res)\n    })\n  }\n\n  const done = (err) => {\n    if (err) {\n      return self.emit('error', err)\n    }\n    self.emit('ready')\n    self.log('boot:done', err)\n  }\n\n  const tasks = []\n\n  // check if there as a repo and if so open it\n  maybeOpenRepo((err, hasRepo) => {\n    if (err) {\n      return done(err)\n    }\n\n    // No repo, but need should init one\n    if (doInit && !hasRepo) {\n      tasks.push((cb) => self.init(initOptions, cb))\n      // we know we will have a repo for all follwing tasks\n      // if the above succeeds\n      hasRepo = true\n    }\n\n    // Need to set config\n    if (setConfig) {\n      if (!hasRepo) {\n        console.log('WARNING, trying to set config on uninitialized repo, maybe forgot to set \"init: true\"')\n      } else {\n        tasks.push((cb) => {\n          waterfall([\n            (cb) => self.config.get(cb),\n            (config, cb) => {\n              extend(config, options.config)\n              self.config.replace(config, cb)\n            }\n          ], cb)\n        })\n      }\n    }\n\n    // Need to start up the node\n    if (doStart) {\n      if (!hasRepo) {\n        console.log('WARNING, trying to start ipfs node on uninitialized repo, maybe forgot to set \"init: true\"')\n        return done(new Error('Uninitalized repo'))\n      } else {\n        tasks.push((cb) => self.start(cb))\n      }\n    }\n\n    // Do the actual boot sequence\n    series(tasks, done)\n  })\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs/src/core/components/index.js":"'use strict'\n\nexports.preStart = require('./pre-start')\nexports.start = require('./start')\nexports.stop = require('./stop')\nexports.isOnline = require('./is-online')\nexports.version = require('./version')\nexports.id = require('./id')\nexports.repo = require('./repo')\nexports.init = require('./init')\nexports.bootstrap = require('./bootstrap')\nexports.config = require('./config')\nexports.block = require('./block')\nexports.object = require('./object')\nexports.dag = require('./dag')\nexports.libp2p = require('./libp2p')\nexports.swarm = require('./swarm')\nexports.ping = require('./ping')\nexports.files = require('./files')\nexports.bitswap = require('./bitswap')\nexports.pubsub = require('./pubsub')\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs/src/core/components/pre-start.js":"'use strict'\n\nconst peerId = require('peer-id')\nconst PeerInfo = require('peer-info')\nconst multiaddr = require('multiaddr')\nconst waterfall = require('async/waterfall')\nconst mafmt = require('mafmt')\n\n/*\n * Load stuff from Repo into memory\n */\nmodule.exports = function preStart (self) {\n  return (callback) => {\n    self.log('pre-start')\n\n    waterfall([\n      (cb) => self._repo.config.get(cb),\n      (config, cb) => {\n        const privKey = config.Identity.PrivKey\n\n        peerId.createFromPrivKey(privKey, (err, id) => {\n          cb(err, config, id)\n        })\n      },\n      (config, id, cb) => {\n        self._peerInfo = new PeerInfo(id)\n\n        config.Addresses.Swarm.forEach((addr) => {\n          let ma = multiaddr(addr)\n\n          if (!mafmt.IPFS.matches(ma)) {\n            ma = ma.encapsulate(\n              '/ipfs/' + self._peerInfo.id.toB58String()\n            )\n          }\n\n          self._peerInfo.multiaddr.add(ma)\n        })\n\n        cb()\n      }\n    ], callback)\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs/src/core/components/start.js":"'use strict'\n\nconst series = require('async/series')\nconst Bitswap = require('ipfs-bitswap')\nconst FloodSub = require('libp2p-floodsub')\n\nmodule.exports = (self) => {\n  return (callback) => {\n    callback = callback || function noop () {}\n\n    const done = (err) => {\n      if (err) {\n        self.emit('error', err)\n        return callback(err)\n      }\n\n      self.state.started()\n      self.emit('start')\n      callback()\n    }\n\n    if (self.state.state() !== 'stopped') {\n      return done(new Error('Not able to start from state: ' + self.state.state()))\n    }\n\n    self.log('starting')\n    self.state.start()\n\n    series([\n      (cb) => {\n        self._repo.closed\n          ? self._repo.open(cb)\n          : cb()\n      },\n      (cb) => self.preStart(cb),\n      (cb) => self.libp2p.start(cb)\n    ], (err) => {\n      if (err) {\n        return done(err)\n      }\n\n      self._bitswap = new Bitswap(\n        self._libp2pNode,\n        self._repo.blockstore,\n        self._peerInfoBook\n      )\n\n      self._bitswap.start()\n      self._blockService.goOnline(self._bitswap)\n\n      if (self._options.EXPERIMENTAL.pubsub) {\n        self._pubsub = new FloodSub(self._libp2pNode)\n        self._pubsub.start(done)\n      } else {\n        done()\n      }\n    })\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs-bitswap/src/index.js":"'use strict'\n\nconst waterfall = require('async/waterfall')\nconst reject = require('async/reject')\nconst each = require('async/each')\nconst EventEmitter = require('events').EventEmitter\nconst debug = require('debug')\n\nconst CONSTANTS = require('./constants')\nconst WantManager = require('./components/want-manager')\nconst Network = require('./components/network')\nconst DecisionEngine = require('./components/decision-engine')\n\nconst log = debug('bitswap')\nlog.error = debug('bitswap:error')\n\n/**\n *\n */\nclass Bitswap {\n  /**\n   * Create a new bitswap instance.\n   *\n   * @param {Libp2p} libp2p\n   * @param {Blockstore} blockstore\n   * @param {PeerBook} peerBook\n   * @returns {Bitswap}\n   */\n  constructor (libp2p, blockstore, peerBook) {\n    this.libp2p = libp2p\n    // the network delivers messages\n    this.network = new Network(libp2p, peerBook, this)\n\n    // local database\n    this.blockstore = blockstore\n\n    this.engine = new DecisionEngine(blockstore, this.network)\n\n    // handle message sending\n    this.wm = new WantManager(this.network)\n\n    this.blocksRecvd = 0\n    this.dupBlocksRecvd = 0\n    this.dupDataRecvd = 0\n\n    this.notifications = new EventEmitter()\n    this.notifications.setMaxListeners(CONSTANTS.maxListeners)\n  }\n\n  // handle messages received through the network\n  _receiveMessage (peerId, incoming, callback) {\n    this.engine.messageReceived(peerId, incoming, (err) => {\n      if (err) {\n        log('failed to receive message', incoming)\n      }\n\n      if (incoming.blocks.size === 0) {\n        return callback()\n      }\n\n      const blocks = Array.from(incoming.blocks.values())\n\n      // quickly send out cancels, reduces chances of duplicate block receives\n      const toCancel = blocks\n        .filter((b) => this.wm.wantlist.contains(b.cid))\n        .map((b) => b.cid)\n\n      this.wm.cancelWants(toCancel)\n\n      each(\n        blocks,\n        (b, cb) => this._handleReceivedBlock(peerId, b, cb),\n        callback\n      )\n    })\n  }\n\n  _handleReceivedBlock (peerId, block, callback) {\n    log('received block')\n\n    waterfall([\n      (cb) => this.blockstore.has(block.cid, cb),\n      (has, cb) => {\n        this._updateReceiveCounters(block, has)\n        if (has) {\n          return cb()\n        }\n\n        this._putBlock(block, cb)\n      }\n    ], callback)\n  }\n\n  _updateReceiveCounters (block, exists) {\n    this.blocksRecvd++\n\n    if (exists) {\n      this.dupBlocksRecvd ++\n      this.dupDataRecvd += block.data.length\n    }\n  }\n\n  // handle errors on the receiving channel\n  _receiveError (err) {\n    log.error('ReceiveError: %s', err.message)\n  }\n\n  // handle new peers\n  _onPeerConnected (peerId) {\n    this.wm.connected(peerId)\n  }\n\n  // handle peers being disconnected\n  _onPeerDisconnected (peerId) {\n    this.wm.disconnected(peerId)\n    this.engine.peerDisconnected(peerId)\n  }\n\n  _putBlock (block, callback) {\n    this.blockstore.put(block, (err) => {\n      if (err) {\n        return callback(err)\n      }\n\n      this.notifications.emit(\n        `block:${block.cid.buffer.toString()}`,\n        block\n      )\n      this.engine.receivedBlocks([block.cid])\n      callback()\n    })\n  }\n\n  /**\n   * Return the current wantlist for a given `peerId`\n   *\n   * @param {PeerId} peerId\n   * @returns {Wantlist}\n   */\n  wantlistForPeer (peerId) {\n    return this.engine.wantlistForPeer(peerId)\n  }\n\n  /**\n   * Fetch a given block by cid. If the block is in the local\n   * blockstore it is returned, otherwise the block is added to the wantlist and returned once another node sends it to us.\n   *\n   * @param {CID} cid\n   * @param {function(Error, Block)} callback\n   * @returns {void}\n   */\n  get (cid, callback) {\n    const unwantListeners = {}\n    const blockListeners = {}\n    const cidStr = cid.buffer.toString()\n    const unwantEvent = `unwant:${cidStr}`\n    const blockEvent = `block:${cidStr}`\n\n    log('get: %s', cidStr)\n    const cleanupListener = () => {\n      if (unwantListeners[cidStr]) {\n        this.notifications.removeListener(unwantEvent, unwantListeners[cidStr])\n        delete unwantListeners[cidStr]\n      }\n\n      if (blockListeners[cidStr]) {\n        this.notifications.removeListener(blockEvent, blockListeners[cidStr])\n        delete blockListeners[cidStr]\n      }\n    }\n\n    const addListener = () => {\n      unwantListeners[cidStr] = () => {\n        log(`manual unwant: ${cidStr}`)\n        cleanupListener()\n        this.wm.cancelWants([cid])\n        callback()\n      }\n\n      blockListeners[cidStr] = (block) => {\n        this.wm.cancelWants([cid])\n        cleanupListener(cid)\n        callback(null, block)\n      }\n\n      this.notifications.once(unwantEvent, unwantListeners[cidStr])\n      this.notifications.once(blockEvent, blockListeners[cidStr])\n    }\n\n    this.blockstore.has(cid, (err, has) => {\n      if (err) {\n        return callback(err)\n      }\n\n      if (has) {\n        log('already have block: %s', cidStr)\n        return this.blockstore.get(cid, callback)\n      }\n\n      addListener()\n      this.wm.wantBlocks([cid])\n    })\n  }\n\n  // removes the given cids from the wantlist independent of any ref counts\n  unwant (cids) {\n    if (!Array.isArray(cids)) {\n      cids = [cids]\n    }\n\n    this.wm.unwantBlocks(cids)\n    cids.forEach((cid) => {\n      this.notifications.emit(`unwant:${cid.buffer.toString()}`)\n    })\n  }\n\n  // removes the given keys from the want list\n  cancelWants (cids) {\n    if (!Array.isArray(cids)) {\n      cids = [cids]\n    }\n    this.wm.cancelWants(cids)\n  }\n\n  /**\n   * Put the given block to the underlying blockstore and\n   * send it to nodes that have it in their wantlist.\n   *\n   * @param {Block} block\n   * @param {function(Error)} callback\n   * @returns {void}\n   */\n  put (block, callback) {\n    log('putting block')\n\n    waterfall([\n      (cb) => this.blockstore.has(block.cid, cb),\n      (has, cb) => {\n        if (has) {\n          return cb()\n        }\n\n        this._putBlock(block, cb)\n      }\n    ], callback)\n  }\n\n  /**\n   * Put the given blocks to the underlying blockstore and\n   * send it to nodes that have it them their wantlist.\n   *\n   * @param {Array<Block>} blocks\n   * @param {function(Error)} callback\n   * @returns {void}\n   */\n  putMany (blocks, callback) {\n    waterfall([\n      (cb) => reject(blocks, (b, cb) => {\n        this.blockstore.has(b.cid, cb)\n      }, cb),\n      (newBlocks, cb) => this.blockstore.putMany(newBlocks, (err) => {\n        if (err) {\n          return cb(err)\n        }\n\n        newBlocks.forEach((block) => {\n          this.notifications.emit(\n            `block:${block.cid.buffer.toString()}`,\n            block\n          )\n          this.engine.receivedBlocks([block.cid])\n        })\n        cb()\n      })\n    ], callback)\n  }\n\n  /**\n   * Get the current list of wants.\n   *\n   * @returns {Array<WantlistEntry>}\n   */\n  getWantlist () {\n    return this.wm.wantlist.entries()\n  }\n\n  /**\n   * Get stats about the bitswap node.\n   *\n   * @returns {Object}\n   */\n  stat () {\n    return {\n      wantlist: this.getWantlist(),\n      blocksReceived: this.blocksRecvd,\n      dupBlksReceived: this.dupBlocksRecvd,\n      dupDataReceived: this.dupDataRecvd,\n      peers: this.engine.peers()\n    }\n  }\n\n  /**\n   * Start the bitswap node.\n   *\n   * @returns {void}\n   */\n  start () {\n    this.wm.run()\n    this.network.start()\n    this.engine.start()\n  }\n\n  /**\n   * Stooop the bitswap node.\n   *\n   * @returns {void}\n   */\n  stop () {\n    this.wm.stop(this.libp2p.peerInfo.id)\n    this.network.stop()\n    this.engine.stop()\n  }\n}\n\nmodule.exports = Bitswap\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs-bitswap/src/constants.js":"'use strict'\n\nconst SECOND = 1000\n\nmodule.exports = {\n  maxProvidersPerRequest: 3,\n  providerRequestTimeout: 10 * SECOND,\n  hasBlockTimeout: 15 * SECOND,\n  provideTimeout: 15 * SECOND,\n  kMaxPriority: Math.pow(2, 31) - 1,\n  rebroadcastDelay: 10 * SECOND,\n  maxListeners: 1000\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs-bitswap/src/components/want-manager/index.js":"'use strict'\n\nconst debug = require('debug')\n\nconst Message = require('../../types/message')\nconst Wantlist = require('../../types/wantlist')\nconst CONSTANTS = require('../../constants')\nconst MsgQueue = require('./msg-queue')\n\nconst log = debug('bitswap:wantmanager')\nlog.error = debug('bitswap:wantmanager:error')\n\nmodule.exports = class WantManager {\n  constructor (network) {\n    this.peers = new Map()\n    this.wantlist = new Wantlist()\n\n    this.network = network\n  }\n\n  _addEntries (cids, cancel, force) {\n    const entries = cids.map((cid, i) => {\n      return new Message.Entry(cid, CONSTANTS.kMaxPriority - i, cancel)\n    })\n\n    entries.forEach((e) => {\n      // add changes to our wantlist\n      if (e.cancel) {\n        if (force) {\n          this.wantlist.removeForce(e.cid)\n        } else {\n          this.wantlist.remove(e.cid)\n        }\n      } else {\n        log('adding to wl')\n        this.wantlist.add(e.cid, e.priority)\n      }\n    })\n\n    // broadcast changes\n    for (let p of this.peers.values()) {\n      p.addEntries(entries)\n    }\n  }\n\n  _startPeerHandler (peerId) {\n    let mq = this.peers.get(peerId.toB58String())\n\n    if (mq) {\n      mq.refcnt ++\n      return\n    }\n\n    mq = new MsgQueue(peerId, this.network)\n\n    // new peer, give them the full wantlist\n    const fullwantlist = new Message(true)\n\n    for (let entry of this.wantlist.entries()) {\n      fullwantlist.addEntry(entry[1].cid, entry[1].priority)\n    }\n\n    mq.addMessage(fullwantlist)\n\n    this.peers.set(peerId.toB58String(), mq)\n    return mq\n  }\n\n  _stopPeerHandler (peerId) {\n    const mq = this.peers.get(peerId.toB58String())\n\n    if (!mq) {\n      return\n    }\n\n    mq.refcnt --\n    if (mq.refcnt > 0) {\n      return\n    }\n\n    this.peers.delete(peerId.toB58String())\n  }\n\n  // add all the cids to the wantlist\n  wantBlocks (cids) {\n    this._addEntries(cids, false)\n  }\n\n  // remove blocks of all the given keys without respecting refcounts\n  unwantBlocks (cids) {\n    log('unwant blocks: %s', cids.length)\n    this._addEntries(cids, true, true)\n  }\n\n  // cancel wanting all of the given keys\n  cancelWants (cids) {\n    log('cancel wants: %s', cids.length)\n    this._addEntries(cids, true)\n  }\n\n  // Returns a list of all currently connected peers\n  connectedPeers () {\n    return Array.from(this.peers.keys())\n  }\n\n  connected (peerId) {\n    this._startPeerHandler(peerId)\n  }\n\n  disconnected (peerId) {\n    this._stopPeerHandler(peerId)\n  }\n\n  run () {\n    this.timer = setInterval(() => {\n      // resend entirew wantlist every so often\n      const fullwantlist = new Message(true)\n      for (let entry of this.wantlist.entries()) {\n        fullwantlist.addEntry(entry[1].cid, entry[1].priority)\n      }\n\n      this.peers.forEach((p) => {\n        p.addMessage(fullwantlist)\n      })\n    }, 10 * 1000)\n  }\n\n  stop () {\n    for (let mq of this.peers.values()) {\n      this.disconnected(mq.peerId)\n    }\n    clearInterval(this.timer)\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs-bitswap/src/types/message/index.js":"'use strict'\n\nconst protobuf = require('protocol-buffers')\nconst Block = require('ipfs-block')\nconst isEqualWith = require('lodash.isequalwith')\nconst assert = require('assert')\nconst each = require('async/each')\nconst CID = require('cids')\nconst codecName = require('multicodec/src/name-table')\nconst vd = require('varint-decoder')\nconst multihashing = require('multihashing-async')\n\nconst pbm = protobuf(require('./message.proto'))\nconst Entry = require('./entry')\n\nclass BitswapMessage {\n  constructor (full) {\n    this.full = full\n    this.wantlist = new Map()\n    this.blocks = new Map()\n  }\n\n  get empty () {\n    return this.blocks.size === 0 &&\n           this.wantlist.size === 0\n  }\n\n  addEntry (cid, priority, cancel) {\n    assert(cid && CID.isCID(cid), 'must be a valid cid')\n    const cidStr = cid.buffer.toString()\n\n    const entry = this.wantlist.get(cidStr)\n\n    if (entry) {\n      entry.priority = priority\n      entry.cancel = Boolean(cancel)\n    } else {\n      this.wantlist.set(cidStr, new Entry(cid, priority, cancel))\n    }\n  }\n\n  addBlock (block) {\n    assert(Block.isBlock(block), 'must be a valid cid')\n    const cidStr = block.cid.buffer.toString()\n    this.blocks.set(cidStr, block)\n  }\n\n  cancel (cid) {\n    assert(CID.isCID(cid), 'must be a valid cid')\n    const cidStr = cid.buffer.toString()\n    this.wantlist.delete(cidStr)\n    this.addEntry(cid, 0, true)\n  }\n\n  /*\n   * Serializes to Bitswap Message protobuf of\n   * version 1.0.0\n   */\n  serializeToBitswap100 () {\n    const msg = {\n      wantlist: {\n        entries: Array.from(this.wantlist.values()).map((entry) => {\n          return {\n            block: entry.cid.buffer, // cid\n            priority: Number(entry.priority),\n            cancel: Boolean(entry.cancel)\n          }\n        })\n      },\n      blocks: Array.from(this.blocks.values())\n        .map((block) => block.data)\n    }\n\n    if (this.full) {\n      msg.wantlist.full = true\n    }\n\n    return pbm.Message.encode(msg)\n  }\n\n  /*\n   * Serializes to Bitswap Message protobuf of\n   * version 1.1.0\n   */\n  serializeToBitswap110 () {\n    const msg = {\n      wantlist: {\n        entries: Array.from(this.wantlist.values()).map((entry) => {\n          return {\n            block: entry.cid.buffer, // cid\n            priority: Number(entry.priority),\n            cancel: Boolean(entry.cancel)\n          }\n        })\n      },\n      payload: []\n    }\n\n    if (this.full) {\n      msg.wantlist.full = true\n    }\n\n    this.blocks.forEach((block) => {\n      msg.payload.push({\n        prefix: block.cid.prefix,\n        data: block.data\n      })\n    })\n\n    return pbm.Message.encode(msg)\n  }\n\n  equals (other) {\n    const cmp = (a, b) => {\n      if (a.equals && typeof a.equals === 'function') {\n        return a.equals(b)\n      }\n    }\n\n    if (this.full !== other.full ||\n        !isEqualWith(this.wantlist, other.wantlist, cmp) ||\n        !isEqualWith(this.blocks, other.blocks, cmp)\n       ) {\n      return false\n    }\n\n    return true\n  }\n\n  get [Symbol.toStringTag] () {\n    const list = Array.from(this.wantlist.keys())\n    const blocks = Array.from(this.blocks.keys())\n    return `BitswapMessage <full: ${this.full}, list: ${list}, blocks: ${blocks}>`\n  }\n}\n\nBitswapMessage.deserialize = (raw, callback) => {\n  let decoded\n  try {\n    decoded = pbm.Message.decode(raw)\n  } catch (err) {\n    return setImmediate(() => callback(err))\n  }\n\n  const isFull = (decoded.wantlist && decoded.wantlist.full) || false\n  const msg = new BitswapMessage(isFull)\n\n  if (decoded.wantlist) {\n    decoded.wantlist.entries.forEach((entry) => {\n      // note: entry.block is the CID here\n      const cid = new CID(entry.block)\n      msg.addEntry(cid, entry.priority, entry.cancel)\n    })\n  }\n\n  // Bitswap 1.0.0\n  // decoded.blocks are just the byte arrays\n  if (decoded.blocks.length > 0) {\n    return each(decoded.blocks, (b, cb) => {\n      multihashing(b, 'sha2-256', (err, hash) => {\n        if (err) {\n          return cb(err)\n        }\n        const cid = new CID(hash)\n        msg.addBlock(new Block(b, cid))\n        cb()\n      })\n    }, (err) => {\n      if (err) {\n        return callback(err)\n      }\n      callback(null, msg)\n    })\n  }\n\n  // Bitswap 1.1.0\n  if (decoded.payload.length > 0) {\n    return each(decoded.payload, (p, cb) => {\n      if (!p.prefix || !p.data) {\n        cb()\n      }\n      const values = vd(p.prefix)\n      const cidVersion = values[0]\n      const multicodec = values[1]\n      const hashAlg = values[2]\n      // const hashLen = values[3] // We haven't need to use this so far\n      multihashing(p.data, hashAlg, (err, hash) => {\n        if (err) {\n          return cb(err)\n        }\n\n        const cid = new CID(cidVersion, codecName[multicodec.toString('16')], hash)\n\n        msg.addBlock(new Block(p.data, cid))\n        cb()\n      })\n    }, (err) => {\n      if (err) {\n        return callback(err)\n      }\n      callback(null, msg)\n    })\n  }\n\n  callback(null, msg)\n}\n\nBitswapMessage.Entry = Entry\nmodule.exports = BitswapMessage\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs-bitswap/src/types/message/message.proto.js":"'use strict'\n\n// from: https://github.com/ipfs/go-ipfs/blob/master/exchange/bitswap/message/pb/message.proto\n\nmodule.exports = `\n  message Message {\n    message Wantlist {\n      message Entry {\n        // changed from string to bytes, it makes a difference in JavaScript\n        optional bytes block = 1;      // the block cid (cidV0 in bitswap 1.0.0, cidV1 in bitswap 1.1.0)\n        optional int32 priority = 2;    // the priority (normalized). default to 1\n        optional bool cancel = 3;       // whether this revokes an entry\n      }\n\n      repeated Entry entries = 1;       // a list of wantlist entries\n      optional bool full = 2;           // whether this is the full wantlist. default to false\n    }\n\n    message Block {\n      optional bytes prefix = 1;        // CID prefix (cid version, multicodec and multihash prefix (type + length)\n      optional bytes data = 2;\n    }\n\n    optional Wantlist wantlist = 1;\n    repeated bytes blocks = 2;          // used to send Blocks in bitswap 1.0.0\n    repeated Block payload = 3;         // used to send Blocks in bitswap 1.1.0\n  }\n`\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs-bitswap/src/types/message/entry.js":"'use strict'\n\nconst WantlistEntry = require('../wantlist').Entry\nconst CID = require('cids')\nconst assert = require('assert')\n\nmodule.exports = class BitswapMessageEntry {\n  constructor (cid, priority, cancel) {\n    assert(CID.isCID(cid), 'needs valid cid')\n    this.entry = new WantlistEntry(cid, priority)\n    this.cancel = Boolean(cancel)\n  }\n\n  get cid () {\n    return this.entry.cid\n  }\n\n  set cid (cid) {\n    this.entry.cid = cid\n  }\n\n  get priority () {\n    return this.entry.priority\n  }\n\n  set priority (val) {\n    this.entry.priority = val\n  }\n\n  get [Symbol.toStringTag] () {\n    const cidStr = this.cid.toBaseEncodedString()\n\n    return `BitswapMessageEntry ${cidStr} <cancel: ${this.cancel}, priority: ${this.priority}>`\n  }\n\n  equals (other) {\n    return (this.cancel === other.cancel) &&\n           this.entry.equals(other.entry)\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs-bitswap/src/types/wantlist/index.js":"'use strict'\n\nconst sort = require('lodash.sortby')\nconst Entry = require('./entry')\n\nclass Wantlist {\n  constructor () {\n    this.set = new Map()\n  }\n\n  get length () {\n    return this.set.size\n  }\n\n  add (cid, priority) {\n    const cidStr = cid.buffer.toString()\n    const entry = this.set.get(cidStr)\n\n    if (entry) {\n      entry.inc()\n      entry.priority = priority\n    } else {\n      this.set.set(cidStr, new Entry(cid, priority))\n    }\n  }\n\n  remove (cid) {\n    const cidStr = cid.buffer.toString()\n    const entry = this.set.get(cidStr)\n\n    if (!entry) {\n      return\n    }\n\n    entry.dec()\n\n    // only delete when no refs are held\n    if (entry.hasRefs()) {\n      return\n    }\n\n    this.set.delete(cidStr)\n  }\n\n  removeForce (cidStr) {\n    if (this.set.has(cidStr)) {\n      this.set.delete(cidStr)\n    }\n  }\n\n  entries () {\n    return this.set.entries()\n  }\n\n  sortedEntries () {\n    return new Map(\n      sort(Array.from(this.set.entries()), (o) => {\n        return o[1].key\n      })\n    )\n  }\n\n  contains (cid) {\n    const cidStr = cid.buffer.toString()\n    return this.set.get(cidStr)\n  }\n}\n\nWantlist.Entry = Entry\nmodule.exports = Wantlist\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs-bitswap/src/types/wantlist/entry.js":"'use strict'\n\nconst assert = require('assert')\nconst CID = require('cids')\n\nclass WantListEntry {\n  constructor (cid, priority) {\n    assert(CID.isCID(cid), 'must be valid CID')\n\n    // Keep track of how many requests we have for this key\n    this._refCounter = 1\n\n    this.cid = cid\n    this.priority = priority || 1\n  }\n\n  inc () {\n    this._refCounter += 1\n  }\n\n  dec () {\n    this._refCounter = Math.max(0, this._refCounter - 1)\n  }\n\n  hasRefs () {\n    return this._refCounter > 0\n  }\n\n  // So that console.log prints a nice description of this object\n  get [Symbol.toStringTag] () {\n    const cidStr = this.cid.toBaseEncodedString()\n    return `WantlistEntry <key: ${cidStr}, priority: ${this.priority}, refs: ${this._refCounter}>`\n  }\n\n  equals (other) {\n    return (this._refCounter === other._refCounter) &&\n      this.cid.equals(other.cid) &&\n      this.priority === other.priority\n  }\n}\n\nmodule.exports = WantListEntry\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs-bitswap/src/components/want-manager/msg-queue.js":"'use strict'\n\nconst debug = require('debug')\nconst debounce = require('lodash.debounce')\nconst Message = require('../../types/message')\n\nconst log = debug('bitswap:wantmanager:queue')\nlog.error = debug('bitswap:wantmanager:queue:error')\n\nmodule.exports = class MsgQueue {\n  constructor (peerId, network) {\n    this.peerId = peerId\n    this.network = network\n    this.refcnt = 1\n\n    this._entries = []\n    this.sendEntries = debounce(this._sendEntries.bind(this), 200)\n  }\n\n  addMessage (msg) {\n    if (msg.empty) {\n      return\n    }\n\n    this.send(msg)\n  }\n\n  addEntries (entries) {\n    this._entries = this._entries.concat(entries)\n    this.sendEntries()\n  }\n\n  _sendEntries () {\n    if (!this._entries.length) {\n      return\n    }\n\n    const msg = new Message(false)\n    this._entries.forEach((entry) => {\n      if (entry.cancel) {\n        msg.cancel(entry.cid)\n      } else {\n        msg.addEntry(entry.cid, entry.priority)\n      }\n    })\n    this._entries = []\n    this.addMessage(msg)\n  }\n\n  send (msg) {\n    this.network.connectTo(this.peerId, (err) => {\n      if (err) {\n        log.error('cant connect to peer %s: %s', this.peerId.toB58String(), err.message)\n        return\n      }\n      log('sending message')\n      this.network.sendMessage(this.peerId, msg, (err) => {\n        if (err) {\n          log.error('send error: %s', err.message)\n        }\n      })\n    })\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs-bitswap/src/components/network/index.js":"'use strict'\n\nconst debug = require('debug')\nconst lp = require('pull-length-prefixed')\nconst pull = require('pull-stream')\nconst setImmediate = require('async/setImmediate')\n\nconst Message = require('../../types/message')\nconst CONSTANTS = require('../../constants')\nconst log = debug('bitswap:network')\nlog.error = debug('bitswap:network:error')\n\nconst BITSWAP100 = '/ipfs/bitswap/1.0.0'\nconst BITSWAP110 = '/ipfs/bitswap/1.1.0'\n\nclass Network {\n  constructor (libp2p, peerBook, bitswap, b100Only) {\n    this.libp2p = libp2p\n    this.peerBook = peerBook\n    this.bitswap = bitswap\n    this.b100Only = b100Only || false\n\n    // increase event listener max\n    this._running = false\n    this.libp2p.swarm.setMaxListeners(CONSTANTS.maxListeners)\n  }\n\n  start () {\n    this._running = true\n    // bind event listeners\n    this._onPeerMux = this._onPeerMux.bind(this)\n    this._onPeerMuxClosed = this._onPeerMuxClosed.bind(this)\n\n    this._onConnection = this._onConnection.bind(this)\n    this.libp2p.handle(BITSWAP100, this._onConnection)\n    if (!this.b100Only) {\n      this.libp2p.handle(BITSWAP110, this._onConnection)\n    }\n\n    this.libp2p.swarm.on('peer-mux-established', this._onPeerMux)\n    this.libp2p.swarm.on('peer-mux-closed', this._onPeerMuxClosed)\n\n    // All existing connections are like new ones for us\n    const pKeys = Object.keys(this.peerBook.getAll())\n    pKeys.forEach((k) => {\n      this._onPeerMux(this.peerBook.getByB58String(k))\n    })\n  }\n\n  stop () {\n    this._running = false\n\n    this.libp2p.unhandle(BITSWAP100)\n    if (!this.b100Only) {\n      this.libp2p.unhandle(BITSWAP110)\n    }\n\n    this.libp2p.swarm.removeListener('peer-mux-established', this._onPeerMux)\n    this.libp2p.swarm.removeListener('peer-mux-closed', this._onPeerMuxClosed)\n  }\n\n  // Handles both types of bitswap messgages\n  _onConnection (protocol, conn) {\n    if (!this._running) {\n      return\n    }\n    log('incomming new bitswap connection: %s', protocol)\n    pull(\n      conn,\n      lp.decode(),\n      pull.asyncMap((data, cb) => Message.deserialize(data, cb)),\n      pull.asyncMap((msg, cb) => {\n        conn.getPeerInfo((err, peerInfo) => {\n          if (err) {\n            return cb(err)\n          }\n          // log('data from', peerInfo.id.toB58String())\n          this.bitswap._receiveMessage(peerInfo.id, msg, cb)\n        })\n      }),\n      pull.onEnd((err) => {\n        log('ending connection')\n        if (err) {\n          return this.bitswap._receiveError(err)\n        }\n      })\n    )\n  }\n\n  _onPeerMux (peerInfo) {\n    if (!this._running) {\n      return\n    }\n    this.bitswap._onPeerConnected(peerInfo.id)\n  }\n\n  _onPeerMuxClosed (peerInfo) {\n    if (!this._running) {\n      return\n    }\n    this.bitswap._onPeerDisconnected(peerInfo.id)\n  }\n\n  // Connect to the given peer\n  connectTo (peerId, callback) {\n    const done = (err) => setImmediate(() => callback(err))\n\n    if (!this._running) {\n      return done(new Error('No running network'))\n    }\n\n    // NOTE: For now, all this does is ensure that we are\n    // connected. Once we have Peer Routing, we will be able\n    // to find the Peer\n    if (this.libp2p.swarm.muxedConns[peerId.toB58String()]) {\n      done()\n    } else {\n      done(new Error('Could not connect to peer with peerId:', peerId.toB58String()))\n    }\n  }\n\n  // Send the given msg (instance of Message) to the given peer\n  sendMessage (peerId, msg, callback) {\n    if (!this._running) {\n      return callback(new Error('No running network'))\n    }\n\n    const stringId = peerId.toB58String()\n    log('sendMessage to %s', stringId, msg)\n    let peerInfo\n    try {\n      peerInfo = this.peerBook.getByB58String(stringId)\n    } catch (err) {\n      return callback(err)\n    }\n\n    this._dialPeer(peerInfo, (err, conn, protocol) => {\n      if (err) {\n        return callback(err)\n      }\n\n      let serialized\n      switch (protocol) {\n        case BITSWAP100:\n          serialized = msg.serializeToBitswap100()\n          break\n        case BITSWAP110:\n          serialized = msg.serializeToBitswap110()\n          break\n        default:\n          return callback(new Error('Unkown protocol: ' + protocol))\n      }\n      writeMessage(conn, serialized, (err) => {\n        if (err) {\n          log(err)\n        }\n      })\n      callback()\n    })\n  }\n\n  _dialPeer (peerInfo, callback) {\n    // dialByPeerInfo throws if no network is there\n    try {\n     // Attempt Bitswap 1.1.0\n      this.libp2p.dialByPeerInfo(peerInfo, BITSWAP110, (err, conn) => {\n        if (err) {\n          // Attempt Bitswap 1.0.0\n          this.libp2p.dialByPeerInfo(peerInfo, BITSWAP100, (err, conn) => {\n            if (err) {\n              return callback(err)\n            }\n\n            callback(null, conn, BITSWAP100)\n          })\n          return\n        }\n\n        callback(null, conn, BITSWAP110)\n      })\n    } catch (err) {\n      return callback(err)\n    }\n  }\n}\n\nfunction writeMessage (conn, msg, callback) {\n  pull(\n    pull.values([msg]),\n    lp.encode(),\n    conn,\n    pull.onEnd(callback)\n  )\n}\n\nmodule.exports = Network\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs-bitswap/src/components/decision-engine/index.js":"'use strict'\n\nconst debug = require('debug')\nconst each = require('async/each')\nconst eachSeries = require('async/eachSeries')\nconst waterfall = require('async/waterfall')\nconst map = require('async/map')\nconst debounce = require('lodash.debounce')\nconst uniqWith = require('lodash.uniqwith')\nconst find = require('lodash.find')\nconst values = require('lodash.values')\nconst groupBy = require('lodash.groupby')\nconst pullAllWith = require('lodash.pullallwith')\n\nconst log = debug('bitswap:engine')\nlog.error = debug('bitswap:engine:error')\n\nconst Message = require('../../types/message')\nconst Wantlist = require('../../types/wantlist')\nconst Ledger = require('./ledger')\n\nconst MAX_MESSAGE_SIZE = 512 * 1024\n\nclass DecisionEngine {\n  constructor (blockstore, network) {\n    this.blockstore = blockstore\n    this.network = network\n\n    // A list of of ledgers by their partner id\n    this.ledgerMap = new Map()\n    this._running = false\n\n    // List of tasks to be processed\n    this._tasks = []\n\n    this._outbox = debounce(this._processTasks.bind(this), 100)\n  }\n\n  _sendBlocks (env, cb) {\n    // split into messges of max 512 * 1024 bytes\n    const blocks = env.blocks\n    const total = blocks.reduce((acc, b) => {\n      return acc + b.data.byteLength\n    }, 0)\n\n    if (total < MAX_MESSAGE_SIZE) {\n      return this._sendSafeBlocks(env.peer, blocks, cb)\n    }\n\n    let size = 0\n    let batch = []\n\n    eachSeries(blocks, (b, cb) => {\n      batch.push(b)\n      size += b.data.byteLength\n\n      if (size >= MAX_MESSAGE_SIZE) {\n        const nextBatch = batch.slice()\n        batch = []\n        this._sendSafeBlocks(env.peer, nextBatch, cb)\n      } else {\n        cb()\n      }\n    }, cb)\n  }\n\n  _sendSafeBlocks (peer, blocks, cb) {\n    const msg = new Message(false)\n\n    blocks.forEach((b) => {\n      msg.addBlock(b)\n    })\n\n    // console.log('sending %s blocks', msg.blocks.size)\n    this.network.sendMessage(peer, msg, (err) => {\n      if (err) {\n        log('sendblock error: %s', err.message)\n      }\n      cb()\n    })\n  }\n\n  _processTasks () {\n    if (!this._running || !this._tasks.length) {\n      return\n    }\n\n    const tasks = this._tasks\n    this._tasks = []\n    const entries = tasks.map((t) => t.entry)\n    const cids = entries.map((e) => e.cid)\n    const uniqCids = uniqWith(cids, (a, b) => a.equals(b))\n    const groupedTasks = groupBy(tasks, (task) => task.target.toB58String())\n\n    waterfall([\n      (cb) => map(uniqCids, (cid, cb) => {\n        this.blockstore.get(cid, cb)\n      }, cb),\n      (blocks, cb) => each(values(groupedTasks), (tasks, cb) => {\n        // all tasks have the same target\n        const peer = tasks[0].target\n        const blockList = cids.map((cid) => {\n          return find(blocks, (b) => b.cid.equals(cid))\n        })\n\n        this._sendBlocks({\n          peer: peer,\n          blocks: blockList\n        }, (err) => {\n          if (err) {\n            log.error('failed to send', err)\n          }\n          blockList.forEach((block) => {\n            this.messageSent(peer, block)\n          })\n          cb()\n        })\n      })\n    ], (err) => {\n      this._tasks = []\n      if (err) {\n        log.error(err)\n      }\n    })\n  }\n\n  wantlistForPeer (peerId) {\n    const peerIdStr = peerId.toB58String()\n    if (!this.ledgerMap.has(peerIdStr)) {\n      return new Map()\n    }\n\n    return this.ledgerMap.get(peerIdStr).wantlist.sortedEntries()\n  }\n\n  peers () {\n    return Array.from(this.ledgerMap.values()).map((l) => l.partner)\n  }\n\n  receivedBlocks (cids) {\n    if (!cids.length) {\n      return\n    }\n    // Check all connected peers if they want the block we received\n    this.ledgerMap.forEach((ledger) => {\n      cids\n        .map((cid) => ledger.wantlistContains(cid))\n        .filter(Boolean)\n        .forEach((entry) => {\n          this._tasks.push({\n            entry: entry,\n            target: ledger.partner\n          })\n        })\n    })\n    this._outbox()\n  }\n\n  // Handle incoming messages\n  messageReceived (peerId, msg, cb) {\n    const ledger = this._findOrCreate(peerId)\n\n    if (msg.empty) {\n      return cb()\n    }\n\n    // If the message was a full wantlist clear the current one\n    if (msg.full) {\n      ledger.wantlist = new Wantlist()\n    }\n\n    this._processBlocks(msg.blocks, ledger)\n\n    if (msg.wantlist.size === 0) {\n      return cb()\n    }\n\n    let cancels = []\n    let wants = []\n    msg.wantlist.forEach((entry) => {\n      if (entry.cancel) {\n        ledger.cancelWant(entry.cid)\n        cancels.push(entry)\n      } else {\n        ledger.wants(entry.cid, entry.priority)\n        wants.push(entry)\n      }\n    })\n\n    this._cancelWants(ledger, peerId, cancels)\n    this._addWants(ledger, peerId, wants, cb)\n  }\n\n  _cancelWants (ledger, peerId, entries) {\n    const id = peerId.toB58String()\n\n    pullAllWith(this._tasks, entries, (t, e) => {\n      const sameTarget = t.target.toB58String() === id\n      const sameCid = t.entry.cid.equals(e.cid)\n      return sameTarget && sameCid\n    })\n  }\n\n  _addWants (ledger, peerId, entries, cb) {\n    each(entries, (entry, cb) => {\n      // If we already have the block, serve it\n      this.blockstore.has(entry.cid, (err, exists) => {\n        if (err) {\n          log.error('failed existence check')\n        } else if (exists) {\n          this._tasks.push({\n            entry: entry.entry,\n            target: peerId\n          })\n        }\n        cb()\n      })\n    }, () => {\n      this._outbox()\n      cb()\n    })\n  }\n\n  _processBlocks (blocks, ledger, callback) {\n    const cids = []\n    blocks.forEach((b, cidStr) => {\n      log('got block (%s bytes)', b.data.length)\n      ledger.receivedBytes(b.data.length)\n      cids.push(b.cid)\n    })\n\n    this.receivedBlocks(cids)\n  }\n\n  // Clear up all accounting things after message was sent\n  messageSent (peerId, block) {\n    const ledger = this._findOrCreate(peerId)\n    ledger.sentBytes(block ? block.data.length : 0)\n    if (block && block.cid) {\n      ledger.wantlist.remove(block.cid)\n    }\n  }\n\n  numBytesSentTo (peerId) {\n    return this._findOrCreate(peerId).accounting.bytesSent\n  }\n\n  numBytesReceivedFrom (peerId) {\n    return this._findOrCreate(peerId).accounting.bytesRecv\n  }\n\n  peerDisconnected (peerId) {\n    // if (this.ledgerMap.has(peerId.toB58String())) {\n    //   this.ledgerMap.delete(peerId.toB58String())\n    // }\n    //\n    // TODO: figure out how to remove all other references\n    // in the peer request queue\n  }\n\n  _findOrCreate (peerId) {\n    const peerIdStr = peerId.toB58String()\n    if (this.ledgerMap.has(peerIdStr)) {\n      return this.ledgerMap.get(peerIdStr)\n    }\n\n    const l = new Ledger(peerId)\n\n    this.ledgerMap.set(peerIdStr, l)\n\n    return l\n  }\n\n  start () {\n    this._running = true\n  }\n\n  stop () {\n    this._running = false\n  }\n}\n\nmodule.exports = DecisionEngine\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs-bitswap/src/components/decision-engine/ledger.js":"'use strict'\n\nconst Wantlist = require('../../types/wantlist')\n\nclass Ledger {\n  constructor (peerId) {\n    this.partner = peerId\n    this.wantlist = new Wantlist()\n\n    this.exchangeCount = 0\n    this.sentToPeer = new Map()\n\n    this.accounting = {\n      bytesSent: 0,\n      bytesRecv: 0\n    }\n  }\n\n  sentBytes (n) {\n    this.exchangeCount++\n    this.lastExchange = (new Date()).getTime()\n    this.accounting.bytesSent += n\n  }\n\n  receivedBytes (n) {\n    this.exchangeCount++\n    this.lastExchange = (new Date()).getTime()\n    this.accounting.bytesRecv += n\n  }\n\n  wants (cid, priority) {\n    this.wantlist.add(cid, priority)\n  }\n\n  cancelWant (cid) {\n    this.wantlist.remove(cid)\n  }\n\n  wantlistContains (cid) {\n    return this.wantlist.contains(cid)\n  }\n}\n\nmodule.exports = Ledger\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs/src/core/components/stop.js":"'use strict'\n\nconst series = require('async/series')\n\nmodule.exports = (self) => {\n  return (callback) => {\n    callback = callback || function noop () {}\n    self.log('stop')\n\n    const done = (err) => {\n      if (err) {\n        self.emit('error', err)\n        return callback(err)\n      }\n      self.state.stopped()\n      self.emit('stop')\n      callback()\n    }\n\n    if (self.state.state() !== 'running') {\n      return done(new Error('Not able to stop from state: ' + self.state.state()))\n    }\n\n    self.state.stop()\n    self._blockService.goOffline()\n    self._bitswap.stop()\n\n    series([\n      (cb) => {\n        if (self._options.EXPERIMENTAL.pubsub) {\n          self._pubsub.stop(cb)\n        } else {\n          cb()\n        }\n      },\n      (cb) => self.libp2p.stop(cb),\n      (cb) => self._repo.close(cb)\n    ], done)\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs/src/core/components/is-online.js":"'use strict'\n\nmodule.exports = function isOnline (self) {\n  return () => {\n    return Boolean(self._bitswap && self._libp2pNode)\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs/src/core/components/version.js":"'use strict'\n\nconst pkg = require('../../../package.json')\nconst promisify = require('promisify-es6')\n\nmodule.exports = function version (self) {\n  return promisify((opts, callback) => {\n    if (typeof opts === 'function') {\n      callback = opts\n      opts = {}\n    }\n\n    callback(null, {\n      version: pkg.version,\n      repo: '',\n      commit: ''\n    })\n  })\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs/src/core/components/id.js":"'use strict'\n\nconst promisify = require('promisify-es6')\n\nmodule.exports = function id (self) {\n  return promisify((opts, callback) => {\n    if (typeof opts === 'function') {\n      callback = opts\n      opts = {}\n    }\n\n    setImmediate(() => callback(null, {\n      id: self._peerInfo.id.toB58String(),\n      publicKey: self._peerInfo.id.pubKey.bytes.toString('base64'),\n      addresses: self._peerInfo.multiaddrs\n                               .map((ma) => ma.toString())\n                               .sort(),\n      agentVersion: 'js-ipfs',\n      protocolVersion: '9000'\n    }))\n  })\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs/src/core/components/repo.js":"'use strict'\n\nmodule.exports = function repo (self) {\n  return {\n    init: (bits, empty, callback) => {\n      // 1. check if repo already exists\n    },\n\n    version: (callback) => {\n      self._repo.version.get(callback)\n    },\n\n    gc: function () {},\n\n    path: () => self._repo.path\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs/src/core/components/init.js":"'use strict'\n\nconst peerId = require('peer-id')\nconst waterfall = require('async/waterfall')\nconst parallel = require('async/parallel')\nconst isNode = require('detect-node')\n\nconst addDefaultAssets = require('./init-assets')\n\nmodule.exports = function init (self) {\n  return (opts, callback) => {\n    if (typeof opts === 'function') {\n      callback = opts\n      opts = {}\n    }\n\n    const done = (err, res) => {\n      if (err) {\n        self.emit('error', err)\n        return callback(err)\n      }\n\n      self.state.initialized()\n      self.emit('init')\n      callback(null, res)\n    }\n\n    if (self.state.state() !== 'uninitalized') {\n      return done(new Error('Not able to init from state: ' + self.state.state()))\n    }\n\n    self.state.init()\n    self.log('init')\n\n    opts.emptyRepo = opts.emptyRepo || false\n    opts.bits = Number(opts.bits) || 2048\n    opts.log = opts.log || function () {}\n\n    const config = isNode\n      ? require('../../init-files/default-config-node.json')\n      : require('../../init-files/default-config-browser.json')\n\n    waterfall([\n      // Verify repo does not yet exist.\n      (cb) => self._repo.exists(cb),\n      (exists, cb) => {\n        self.log('repo exists?', exists)\n        if (exists === true) {\n          return cb(new Error('repo already exists'))\n        }\n\n        // Generate peer identity keypair + transform to desired format + add to config.\n        opts.log(`generating ${opts.bits}-bit RSA keypair...`, false)\n        self.log('generating peer id: %s bits', opts.bits)\n        peerId.create({bits: opts.bits}, cb)\n      },\n      (keys, cb) => {\n        self.log('identity generated')\n        config.Identity = {\n          PeerID: keys.toB58String(),\n          PrivKey: keys.privKey.bytes.toString('base64')\n        }\n        opts.log('done')\n        opts.log('peer identity: ' + config.Identity.PeerID)\n\n        self._repo.init(config, cb)\n      },\n      (_, cb) => self._repo.open(cb),\n      (cb) => {\n        self.log('repo opened')\n        if (opts.emptyRepo) {\n          return cb(null, true)\n        }\n\n        const tasks = [\n          // add empty unixfs dir object (go-ipfs assumes this exists)\n          (cb) => self.object.new('unixfs-dir', cb)\n        ]\n\n        if (typeof addDefaultAssets === 'function') {\n          tasks.push((cb) => addDefaultAssets(self, opts.log, cb))\n        }\n\n        parallel(tasks, (err) => {\n          if (err) {\n            return cb(err)\n          }\n\n          cb(null, true)\n        })\n      }\n    ], done)\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs/src/core/components/init-assets.js":"'use strict'\n\nconst path = require('path')\nconst fs = require('fs')\nconst glob = require('glob')\nconst importer = require('ipfs-unixfs-engine').importer\nconst pull = require('pull-stream')\nconst file = require('pull-file')\n// const mh = require('multihashes')\n\n// Add the default assets to the repo.\nmodule.exports = function addDefaultAssets (self, log, callback) {\n  const initDocsPath = path.join(__dirname, '../../init-files/init-docs')\n  const index = __dirname.lastIndexOf('/')\n\n  pull(\n    pull.values([initDocsPath]),\n    pull.asyncMap((val, cb) => {\n      glob(path.join(val, '/**/*'), cb)\n    }),\n    pull.flatten(),\n    pull.map((element) => {\n      const addPath = element.substring(index + 1, element.length)\n      if (fs.statSync(element).isDirectory()) {\n        return\n      }\n\n      return {\n        path: addPath,\n        content: file(element)\n      }\n    }),\n    // Filter out directories, which are undefined from above\n    pull.filter(Boolean),\n    importer(self._ipldResolver),\n    pull.through((el) => {\n      if (el.path === 'files/init-docs/docs') {\n        log('to get started, enter:')\n        log()\n        log(`\\t jsipfs files cat /ipfs/QmPZ9gcCEpqKTo6aq61g2nXGUhM4iCL3ewB6LDXZCtioEB`)\n        // TODO when we support pathing in unixfs-engine\n        // const hash = mh.toB58String(el.multihash)\n        // log(`\\t jsipfs files cat /ipfs/${hash}/readme`)\n        log()\n      }\n    }),\n    pull.collect((err) => {\n      if (err) {\n        return callback(err)\n      }\n\n      callback(null, true)\n    })\n  )\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs-unixfs-engine/src/index.js":"'use strict'\n\nexports.importer = exports.Importer = require('./importer')\nexports.exporter = exports.Exporter = require('./exporter')\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs-unixfs-engine/src/importer/index.js":"'use strict'\n\nconst pause = require('pull-pause')\nconst pull = require('pull-stream')\nconst writable = require('pull-write')\nconst pushable = require('pull-pushable')\nconst assert = require('assert')\nconst setImmediate = require('async/setImmediate')\nconst DAGBuilder = require('../builder')\nconst createTreeBuilder = require('./tree-builder')\n\nconst chunkers = {\n  fixed: require('../chunker/fixed-size')\n}\n\nconst defaultOptions = {\n  chunker: 'fixed'\n}\n\nmodule.exports = function (ipldResolver, _options) {\n  const options = Object.assign({}, defaultOptions, _options)\n  const Chunker = chunkers[options.chunker]\n  assert(Chunker, 'Unknkown chunker named ' + options.chunker)\n\n  let pending = 0\n  const waitingPending = []\n\n  const entry = {\n    sink: writable(\n      (nodes, callback) => {\n        pending += nodes.length\n        nodes.forEach((node) => entry.source.push(node))\n        setImmediate(callback)\n      },\n      null,\n      1,\n      (err) => entry.source.end(err)\n    ),\n    source: pushable()\n  }\n\n  const dagStream = DAGBuilder(Chunker, ipldResolver, options)\n\n  const treeBuilder = createTreeBuilder(ipldResolver, options)\n  const treeBuilderStream = treeBuilder.stream()\n  const pausable = pause(() => {})\n\n  // TODO: transform this entry -> pausable -> <custom async transform> -> exit\n  // into a generic NPM package named something like pull-pause-and-drain\n\n  pull(\n    entry,\n    pausable,\n    dagStream,\n    pull.map((node) => {\n      pending--\n      if (!pending) {\n        process.nextTick(() => {\n          while (waitingPending.length) {\n            waitingPending.shift()()\n          }\n        })\n      }\n      return node\n    }),\n    treeBuilderStream\n    )\n\n  return {\n    sink: entry.sink,\n    source: treeBuilderStream.source,\n    flush: flush\n  }\n\n  function flush (callback) {\n    pausable.pause()\n\n    // wait until all the files entered were\n    // transformed into DAG nodes\n    if (!pending) {\n      proceed()\n    } else {\n      waitingPending.push(proceed)\n    }\n\n    function proceed () {\n      treeBuilder.flush((err, hash) => {\n        if (err) {\n          treeBuilderStream.source.end(err)\n          callback(err)\n          return\n        }\n        pausable.resume()\n        callback(null, hash)\n      })\n    }\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs-unixfs-engine/src/builder/index.js":"'use strict'\n\nconst assert = require('assert')\nconst createBuildStream = require('./create-build-stream')\nconst Builder = require('./builder')\n\nconst reducers = {\n  flat: require('./flat'),\n  balanced: require('./balanced'),\n  trickle: require('./trickle')\n}\n\nconst defaultOptions = {\n  strategy: 'balanced',\n  highWaterMark: 100,\n  reduceSingleLeafToSelf: false\n}\n\nmodule.exports = function (Chunker, ipldResolver, _options) {\n  assert(Chunker, 'Missing chunker creator function')\n  assert(ipldResolver, 'Missing IPLD Resolver')\n\n  const options = Object.assign({}, defaultOptions, _options)\n\n  const strategyName = options.strategy\n  const reducer = reducers[strategyName]\n  assert(reducer, 'Unknown importer build strategy name: ' + strategyName)\n\n  const createStrategy = Builder(Chunker, ipldResolver, reducer, options)\n\n  return createBuildStream(createStrategy, ipldResolver, options)\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs-unixfs-engine/src/builder/create-build-stream.js":"'use strict'\n\nconst pullPushable = require('pull-pushable')\nconst pullWrite = require('pull-write')\n\nmodule.exports = function createBuildStream (createStrategy, ipldResolver, options) {\n  const source = pullPushable()\n\n  const sink = pullWrite(\n    createStrategy(source),\n    null,\n    options.highWaterMark,\n    (err) => source.end(err)\n  )\n\n  return {\n    source: source,\n    sink: sink\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs-unixfs-engine/src/builder/builder.js":"'use strict'\n\nconst extend = require('deep-extend')\nconst UnixFS = require('ipfs-unixfs')\nconst pull = require('pull-stream')\nconst through = require('pull-through')\nconst parallel = require('async/parallel')\nconst waterfall = require('async/waterfall')\nconst dagPB = require('ipld-dag-pb')\nconst CID = require('cids')\n\nconst reduce = require('./reduce')\n\nconst DAGNode = dagPB.DAGNode\n\nconst defaultOptions = {\n  chunkerOptions: {\n    maxChunkSize: 262144\n  }\n}\n\nmodule.exports = function (createChunker, ipldResolver, createReducer, _options) {\n  const options = extend({}, defaultOptions, _options)\n\n  return function (source) {\n    return function (items, cb) {\n      parallel(items.map((item) => (cb) => {\n        if (!item.content) {\n          // item is a directory\n          return createAndStoreDir(item, (err, node) => {\n            if (err) {\n              return cb(err)\n            }\n            if (node) {\n              source.push(node)\n            }\n            cb()\n          })\n        }\n\n        // item is a file\n        createAndStoreFile(item, (err, node) => {\n          if (err) {\n            return cb(err)\n          }\n          if (node) {\n            source.push(node)\n          }\n          cb()\n        })\n      }), cb)\n    }\n  }\n\n  function createAndStoreDir (item, callback) {\n    // 1. create the empty dir dag node\n    // 2. write it to the dag store\n\n    const d = new UnixFS('directory')\n    waterfall([\n      (cb) => DAGNode.create(d.marshal(), cb),\n      (node, cb) => {\n        ipldResolver.put(node, {\n          cid: new CID(node.multihash)\n        }, (err) => cb(err, node))\n      }\n    ], (err, node) => {\n      if (err) {\n        return callback(err)\n      }\n      callback(null, {\n        path: item.path,\n        multihash: node.multihash,\n        size: node.size\n      })\n    })\n  }\n\n  function createAndStoreFile (file, callback) {\n    if (Buffer.isBuffer(file.content)) {\n      file.content = pull.values([file.content])\n    }\n\n    if (typeof file.content !== 'function') {\n      return callback(new Error('invalid content'))\n    }\n\n    const reducer = createReducer(reduce(file, ipldResolver, options), options)\n\n    let previous\n    let count = 0\n\n    pull(\n      file.content,\n      createChunker(options.chunkerOptions),\n      pull.map(chunk => new Buffer(chunk)),\n      pull.map(buffer => new UnixFS('file', buffer)),\n      pull.asyncMap((fileNode, callback) => {\n        DAGNode.create(fileNode.marshal(), (err, node) => {\n          callback(err, { DAGNode: node, fileNode: fileNode })\n        })\n      }),\n      pull.asyncMap((leaf, callback) => {\n        ipldResolver.put(leaf.DAGNode, {\n          cid: new CID(leaf.DAGNode.multihash)\n        }, (err) => callback(err, leaf)\n        )\n      }),\n      pull.map((leaf) => {\n        return {\n          path: file.path,\n          multihash: leaf.DAGNode.multihash,\n          size: leaf.DAGNode.size,\n          leafSize: leaf.fileNode.fileSize(),\n          name: ''\n        }\n      }),\n      through( // mark as single node if only one single node\n        function onData (data) {\n          count++\n          if (previous) {\n            this.queue(previous)\n          }\n          previous = data\n        },\n        function ended () {\n          if (previous) {\n            if (count === 1) {\n              previous.single = true\n            }\n            this.queue(previous)\n          }\n          this.queue(null)\n        }\n      ),\n      reducer,\n      pull.collect((err, roots) => {\n        if (err) {\n          callback(err)\n        } else {\n          callback(null, roots[0])\n        }\n      })\n    )\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs-unixfs/src/index.js":"'use strict'\n\nconst protobuf = require('protocol-buffers')\nconst pb = protobuf(require('./unixfs.proto'))\n// encode/decode\nconst unixfsData = pb.Data\n// const unixfsMetadata = pb.MetaData // encode/decode\n\nconst types = [\n  'raw',\n  'directory',\n  'file',\n  'metadata',\n  'symlink',\n  'hamt-sharded-directory'\n]\n\nfunction Data (type, data) {\n  if (!(this instanceof Data)) {\n    return new Data(type, data)\n  }\n  if (types.indexOf(type) === -1) {\n    throw new Error('Type: ' + type + ' is not valid')\n  }\n\n  this.type = type\n  this.data = data\n  this.blockSizes = []\n\n  this.addBlockSize = (size) => {\n    this.blockSizes.push(size)\n  }\n\n  this.removeBlockSize = (index) => {\n    this.blockSizes.splice(index, 1)\n  }\n\n  // data.length + blockSizes\n  this.fileSize = () => {\n    let sum = 0\n    this.blockSizes.forEach((size) => {\n      sum += size\n    })\n    if (data) {\n      sum += data.length\n    }\n    return sum\n  }\n\n  // encode to protobuf\n  this.marshal = () => {\n    let type\n\n    switch (this.type) {\n      case 'raw': type = unixfsData.DataType.Raw; break\n      case 'directory': type = unixfsData.DataType.Directory; break\n      case 'file': type = unixfsData.DataType.File; break\n      case 'metadata': type = unixfsData.DataType.Metadata; break\n      case 'symlink': type = unixfsData.DataType.Symlink; break\n      case 'hamt-sharded-directory': type = unixfsData.DataType.HAMTShard; break\n      default:\n        throw new Error(`Unkown type: \"${this.type}\"`)\n    }\n    let fileSize = this.fileSize()\n\n    if (fileSize === 0) {\n      fileSize = undefined\n    }\n\n    return unixfsData.encode({\n      Type: type,\n      Data: this.data,\n      filesize: fileSize,\n      blocksizes: this.blockSizes.length > 0 ? this.blockSizes : undefined,\n      hashType: this.hashType,\n      fanout: this.fanout\n    })\n  }\n}\n\n// decode from protobuf https://github.com/ipfs/go-ipfs/blob/master/unixfs/format.go#L24\nData.unmarshal = (marsheled) => {\n  const decoded = unixfsData.decode(marsheled)\n  if (!decoded.Data) {\n    decoded.Data = undefined\n  }\n  const obj = new Data(types[decoded.Type], decoded.Data)\n  obj.blockSizes = decoded.blocksizes\n  return obj\n}\n\nexports = module.exports = Data\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs-unixfs/src/unixfs.proto.js":"'use strict'\n\nmodule.exports = `message Data {\n  enum DataType {\n    Raw = 0;\n    Directory = 1;\n    File = 2;\n    Metadata = 3;\n    Symlink = 4;\n    HAMTShard = 5;\n  }\n\n  required DataType Type = 1;\n  optional bytes Data = 2;\n  optional uint64 filesize = 3;\n  repeated uint64 blocksizes = 4;\n\n  optional uint64 hashType = 5;\n  optional uint64 fanout = 6;\n}\n\nmessage Metadata {\n  required string MimeType = 1;\n}`\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs-unixfs-engine/src/builder/reduce.js":"'use strict'\n\nconst waterfall = require('async/waterfall')\nconst dagPB = require('ipld-dag-pb')\nconst UnixFS = require('ipfs-unixfs')\nconst CID = require('cids')\n\nconst DAGLink = dagPB.DAGLink\nconst DAGNode = dagPB.DAGNode\n\nmodule.exports = function (file, ipldResolver, options) {\n  return function (leaves, callback) {\n    if (leaves.length === 1 && (leaves[0].single || options.reduceSingleLeafToSelf)) {\n      const leave = leaves[0]\n      callback(null, {\n        path: file.path,\n        multihash: leave.multihash,\n        size: leave.size,\n        leafSize: leave.leafSize,\n        name: leave.name\n      })\n      return // early\n    }\n\n    // create a parent node and add all the leafs\n    const f = new UnixFS('file')\n\n    const links = leaves.map((leaf) => {\n      f.addBlockSize(leaf.leafSize)\n\n      return new DAGLink(leaf.name, leaf.size, leaf.multihash)\n    })\n\n    waterfall([\n      (cb) => DAGNode.create(f.marshal(), links, cb),\n      (node, cb) => {\n        ipldResolver.put(node, {\n          cid: new CID(node.multihash)\n        }, (err) => cb(err, node))\n      }\n    ], (err, node) => {\n      if (err) {\n        callback(err)\n        return // early\n      }\n\n      const root = {\n        name: '',\n        path: file.path,\n        multihash: node.multihash,\n        size: node.size,\n        leafSize: f.fileSize()\n      }\n\n      callback(null, root)\n    })\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs-unixfs-engine/src/builder/flat/index.js":"'use strict'\n\nconst pull = require('pull-stream')\nconst pushable = require('pull-pushable')\nconst pullPair = require('pull-pair')\nconst batch = require('pull-batch')\n\nmodule.exports = function (reduce, options) {\n  const pair = pullPair()\n  const source = pair.source\n  const result = pushable()\n\n  pull(\n    source,\n    batch(Infinity),\n    pull.asyncMap(reduce),\n    pull.collect((err, roots) => {\n      if (err) {\n        result.end(err)\n        return // early\n      }\n      if (roots.length === 1) {\n        result.push(roots[0])\n        result.end()\n      } else if (roots.length > 1) {\n        result.end(new Error('expected a maximum of 1 roots and got ' + roots.length))\n      } else {\n        result.end()\n      }\n    })\n  )\n\n  return {\n    sink: pair.sink,\n    source: result\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs-unixfs-engine/src/builder/balanced/index.js":"'use strict'\n\nconst balancedReducer = require('./balanced-reducer')\n\nconst defaultOptions = {\n  maxChildrenPerNode: 174\n}\n\nmodule.exports = function (reduce, _options) {\n  const options = Object.assign({}, defaultOptions, _options)\n  return balancedReducer(reduce, options)\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs-unixfs-engine/src/builder/balanced/balanced-reducer.js":"'use strict'\n\nconst pull = require('pull-stream')\nconst pushable = require('pull-pushable')\nconst pullPair = require('pull-pair')\nconst batch = require('pull-batch')\n\nmodule.exports = function balancedReduceToRoot (reduce, options) {\n  const pair = pullPair()\n  const source = pair.source\n\n  const result = pushable()\n\n  reduceToParents(source, (err, roots) => {\n    if (err) {\n      result.end(err)\n      return // early\n    }\n    if (roots.length === 1) {\n      result.push(roots[0])\n      result.end()\n    } else if (roots.length > 1) {\n      result.end(new Error('expected a maximum of 1 roots and got ' + roots.length))\n    } else {\n      result.end()\n    }\n  })\n\n  function reduceToParents (_chunks, callback) {\n    let chunks = _chunks\n    if (Array.isArray(chunks)) {\n      chunks = pull.values(chunks)\n    }\n\n    pull(\n      chunks,\n      batch(options.maxChildrenPerNode),\n      pull.asyncMap(reduce),\n      pull.collect(reduced)\n    )\n\n    function reduced (err, roots) {\n      if (err) {\n        callback(err)\n      } else if (roots.length > 1) {\n        reduceToParents(roots, callback)\n      } else {\n        callback(null, roots)\n      }\n    }\n  }\n\n  return {\n    sink: pair.sink,\n    source: result\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs-unixfs-engine/src/builder/trickle/index.js":"'use strict'\n\nconst trickleReducer = require('./trickle-reducer')\n\nconst defaultOptions = {\n  maxChildrenPerNode: 174,\n  layerRepeat: 4\n}\n\nmodule.exports = function (reduce, _options) {\n  const options = Object.assign({}, defaultOptions, _options)\n  return trickleReducer(reduce, options)\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs-unixfs-engine/src/builder/trickle/trickle-reducer.js":"'use strict'\n\nconst pull = require('pull-stream')\nconst pushable = require('pull-pushable')\nconst batch = require('pull-batch')\nconst pullPair = require('pull-pair')\nconst through = require('pull-through')\nconst pullWrite = require('pull-write')\nconst pause = require('pull-pause')\n\nmodule.exports = function trickleReduceToRoot (reduce, options) {\n  const pair = pullPair()\n  const result = pushable()\n  const pausable = pause(() => {})\n  let pendingResumes = 0\n\n  pull(\n    pair.source,\n    pausable,\n    trickle(0, -1),\n    batch(Infinity),\n    pull.asyncMap(reduce),\n    pull.collect((err, roots) => {\n      if (err) {\n        result.end(err)\n      } else {\n        if (roots.length === 1) {\n          result.push(roots[0])\n          result.end()\n        } else if (roots.length > 1) {\n          result.end(new Error('expected a maximum of 1 roots and got ' + roots.length))\n        } else {\n          result.end()\n        }\n      }\n    })\n  )\n\n  return {\n    sink: pair.sink,\n    source: result\n  }\n\n  function trickle (indent, maxDepth) {\n    let iteration = 0\n    let depth = 0\n    let deeper\n    let aborting = false\n\n    const result = pushable()\n\n    return {\n      source: result,\n      sink: pullWrite(write, null, 1, end)\n    }\n\n    function write (nodes, callback) {\n      let ended = false\n      const node = nodes[0]\n\n      if (depth && !deeper) {\n        deeper = pushable()\n\n        pull(\n          deeper,\n          trickle(indent + 1, depth - 1),\n          through(\n            function (d) {\n              this.queue(d)\n            },\n            function (err) {\n              if (err) {\n                this.emit('error', err)\n                return // early\n              }\n              if (!ended) {\n                ended = true\n                pendingResumes++\n                pausable.pause()\n              }\n              this.queue(null)\n            }\n          ),\n          batch(Infinity),\n          pull.asyncMap(reduce),\n          pull.collect((err, nodes) => {\n            pendingResumes--\n            if (err) {\n              result.end(err)\n              return\n            }\n            nodes.forEach(node => {\n              result.push(node)\n            })\n            iterate()\n          })\n        )\n      }\n\n      if (deeper) {\n        deeper.push(node)\n      } else {\n        result.push(node)\n        iterate()\n      }\n\n      callback()\n    }\n\n    function iterate () {\n      deeper = null\n      iteration++\n      if ((depth === 0 && iteration === options.maxChildrenPerNode) ||\n          (depth > 0 && iteration === options.layerRepeat)) {\n        iteration = 0\n        depth++\n      }\n\n      if ((!aborting && maxDepth >= 0 && depth > maxDepth) ||\n          (aborting && !pendingResumes)) {\n        aborting = true\n        result.end()\n      }\n\n      if (!pendingResumes) {\n        pausable.resume()\n      }\n    }\n\n    function end (err) {\n      if (err) {\n        result.end(err)\n        return\n      }\n      if (deeper) {\n        if (!aborting) {\n          aborting = true\n          deeper.end()\n        }\n      } else {\n        result.end()\n      }\n    }\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs-unixfs-engine/src/importer/tree-builder.js":"'use strict'\n\nconst eachSeries = require('async/eachSeries')\nconst eachOfSeries = require('async/eachOfSeries')\nconst waterfall = require('async/waterfall')\nconst createQueue = require('async/queue')\nconst writable = require('pull-write')\nconst pushable = require('pull-pushable')\nconst DirFlat = require('./dir-flat')\nconst flatToShard = require('./flat-to-shard')\nconst Dir = require('./dir')\n\nmodule.exports = createTreeBuilder\n\nconst defaultOptions = {\n  wrap: false,\n  shardSplitThreshold: 1000\n}\n\nfunction createTreeBuilder (ipldResolver, _options) {\n  const options = Object.assign({}, defaultOptions, _options)\n\n  const queue = createQueue(consumeQueue, 1)\n\n  // returned stream\n  let stream = createStream()\n\n  // root node\n  let tree = DirFlat({\n    path: '',\n    root: true,\n    dir: true,\n    dirty: false,\n    flat: true\n  })\n\n  return {\n    flush: flushRoot,\n    stream: getStream\n  }\n\n  function consumeQueue (action, callback) {\n    const args = action.args.concat(function () {\n      action.cb.apply(null, arguments)\n      callback()\n    })\n    action.fn.apply(null, args)\n  }\n\n  function getStream () {\n    return stream\n  }\n\n  function createStream () {\n    const sink = writable(write, null, 1, ended)\n    const source = pushable()\n\n    return {\n      sink: sink,\n      source: source\n    }\n\n    function write (elems, callback) {\n      eachSeries(\n        elems,\n        (elem, callback) => {\n          queue.push({\n            fn: addToTree,\n            args: [elem],\n            cb: (err) => {\n              if (err) {\n                callback(err)\n              } else {\n                source.push(elem)\n                callback()\n              }\n            }\n          })\n        },\n        callback\n      )\n    }\n\n    function ended (err) {\n      flushRoot((flushErr) => {\n        source.end(flushErr || err)\n      })\n    }\n  }\n\n  // ---- Add to tree\n\n  function addToTree (elem, callback) {\n    const pathElems = elem.path.split('/').filter(notEmpty)\n    let parent = tree\n    const lastIndex = pathElems.length - 1\n\n    let currentPath = ''\n    eachOfSeries(pathElems, (pathElem, index, callback) => {\n      if (currentPath) {\n        currentPath += '/'\n      }\n      currentPath += pathElem\n\n      const last = (index === lastIndex)\n      parent.dirty = true\n      parent.multihash = null\n      parent.size = null\n\n      if (last) {\n        waterfall([\n          (callback) => parent.put(pathElem, elem, callback),\n          (callback) => flatToShard(null, parent, options.shardSplitThreshold, callback),\n          (newRoot, callback) => {\n            tree = newRoot\n            callback()\n          }\n        ], callback)\n      } else {\n        parent.get(pathElem, (err, treeNode) => {\n          if (err) {\n            callback(err)\n            return // early\n          }\n          let dir = treeNode\n          if (!dir || !(dir instanceof Dir)) {\n            dir = DirFlat({\n              dir: true,\n              parent: parent,\n              parentKey: pathElem,\n              path: currentPath,\n              dirty: true,\n              flat: true\n            })\n          }\n          const parentDir = parent\n          parent = dir\n          parentDir.put(pathElem, dir, callback)\n        })\n      }\n    }, callback)\n  }\n\n  // ---- Flush\n\n  function flushRoot (callback) {\n    queue.push({\n      fn: flush,\n      args: ['', tree],\n      cb: (err, node) => {\n        if (err) {\n          callback(err)\n        } else {\n          callback(null, node && node.multihash)\n        }\n      }\n    })\n  }\n\n  function flush (path, tree, callback) {\n    if (tree.dir) {\n      if (tree.root && tree.childCount() > 1 && !options.wrap) {\n        callback(new Error('detected more than one root'))\n        return // early\n      }\n      tree.eachChildSeries(\n        (key, child, callback) => {\n          flush(path ? (path + '/' + key) : key, child, callback)\n        },\n        (err) => {\n          if (err) {\n            callback(err)\n            return // early\n          }\n          flushDir(path, tree, callback)\n        })\n    } else {\n      // leaf node, nothing to do here\n      process.nextTick(callback)\n    }\n  }\n\n  function flushDir (path, tree, callback) {\n    // don't create a wrapping node unless the user explicitely said so\n    if (tree.root && !options.wrap) {\n      tree.onlyChild((err, onlyChild) => {\n        if (err) {\n          callback(err)\n          return // early\n        }\n\n        callback(null, onlyChild)\n      })\n\n      return // early\n    }\n\n    if (!tree.dirty) {\n      callback(null, tree.multihash)\n      return // early\n    }\n\n    // don't flush directory unless it's been modified\n\n    tree.dirty = false\n    tree.flush(path, ipldResolver, stream.source, (err, node) => {\n      if (err) {\n        callback(err)\n      } else {\n        callback(null, node)\n      }\n    })\n  }\n}\n\nfunction notEmpty (str) {\n  return Boolean(str)\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs-unixfs-engine/src/importer/dir-flat.js":"'use strict'\n\nconst asyncEachSeries = require('async/eachSeries')\nconst waterfall = require('async/waterfall')\nconst CID = require('cids')\nconst dagPB = require('ipld-dag-pb')\nconst UnixFS = require('ipfs-unixfs')\nconst DAGLink = dagPB.DAGLink\nconst DAGNode = dagPB.DAGNode\nconst Dir = require('./dir')\n\nclass DirFlat extends Dir {\n  constructor (props) {\n    super()\n    this._children = {}\n    Object.assign(this, props)\n  }\n\n  put (name, value, callback) {\n    this.multihash = undefined\n    this.size = undefined\n    this._children[name] = value\n    process.nextTick(callback)\n  }\n\n  get (name, callback) {\n    process.nextTick(() => callback(null, this._children[name]))\n  }\n\n  childCount () {\n    return Object.keys(this._children).length\n  }\n\n  directChildrenCount () {\n    return this.childCount()\n  }\n\n  onlyChild (callback) {\n    process.nextTick(() => callback(null, this._children[Object.keys(this._children)[0]]))\n  }\n\n  eachChildSeries (iterator, callback) {\n    asyncEachSeries(\n      Object.keys(this._children),\n      (key, callback) => {\n        iterator(key, this._children[key], callback)\n      },\n      callback\n    )\n  }\n\n  flush (path, ipldResolver, source, callback) {\n    const links = Object.keys(this._children)\n      .map((key) => {\n        const child = this._children[key]\n        return new DAGLink(key, child.size, child.multihash)\n      })\n\n    const dir = new UnixFS('directory')\n    waterfall(\n      [\n        (callback) => DAGNode.create(dir.marshal(), links, callback),\n        (node, callback) => {\n          ipldResolver.put(\n            node,\n            {\n              cid: new CID(node.multihash)\n            },\n            (err) => callback(err, node))\n        },\n        (node, callback) => {\n          this.multihash = node.multihash\n          this.size = node.size\n          const pushable = {\n            path: path,\n            multihash: node.multihash,\n            size: node.size\n          }\n          source.push(pushable)\n          callback(null, node)\n        }\n      ],\n      callback)\n  }\n}\n\nmodule.exports = createDirFlat\n\nfunction createDirFlat (props) {\n  return new DirFlat(props)\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs-unixfs-engine/src/importer/dir.js":"'use strict'\n\nmodule.exports = class Dir {\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs-unixfs-engine/src/importer/flat-to-shard.js":"'use strict'\n\nconst waterfall = require('async/waterfall')\nconst DirSharded = require('./dir-sharded')\n\nmodule.exports = flatToShard\n\nfunction flatToShard (child, dir, threshold, callback) {\n  maybeFlatToShardOne(dir, threshold, (err, newDir) => {\n    if (err) {\n      callback(err)\n      return // early\n    }\n\n    const parent = newDir.parent\n    if (parent) {\n      waterfall([\n        (callback) => {\n          if (newDir !== dir) {\n            if (child) {\n              child.parent = newDir\n            }\n            parent.put(newDir.parentKey, newDir, callback)\n          } else {\n            callback()\n          }\n        },\n        (callback) => {\n          if (parent) {\n            flatToShard(newDir, parent, threshold, callback)\n          } else {\n            callback(null, newDir)\n          }\n        }\n      ], callback)\n    } else {\n      // no parent, we're done climbing tree\n      callback(null, newDir)\n    }\n  })\n}\n\nfunction maybeFlatToShardOne (dir, threshold, callback) {\n  if (dir.flat && dir.directChildrenCount() >= threshold) {\n    definitelyShardOne(dir, callback)\n  } else {\n    callback(null, dir)\n  }\n}\n\nfunction definitelyShardOne (oldDir, callback) {\n  const newDir = DirSharded({\n    root: oldDir.root,\n    dir: true,\n    parent: oldDir.parent,\n    parentKey: oldDir.parentKey,\n    path: oldDir.path,\n    dirty: oldDir.dirty,\n    flat: false\n  })\n\n  oldDir.eachChildSeries(\n    (key, value, callback) => {\n      newDir.put(key, value, callback)\n    },\n    (err) => {\n      if (err) {\n        callback(err)\n      } else {\n        callback(err, newDir)\n      }\n    }\n  )\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs-unixfs-engine/src/importer/dir-sharded.js":"'use strict'\n\nconst leftPad = require('left-pad')\nconst whilst = require('async/whilst')\nconst waterfall = require('async/waterfall')\nconst CID = require('cids')\nconst dagPB = require('ipld-dag-pb')\nconst UnixFS = require('ipfs-unixfs')\nconst DAGLink = dagPB.DAGLink\nconst DAGNode = dagPB.DAGNode\nconst multihashing = require('multihashing-async')\nconst Dir = require('./dir')\n\nconst Bucket = require('../hamt')\n\nconst hashFn = function (value, callback) {\n  multihashing(value, 'murmur3-128', (err, hash) => {\n    if (err) {\n      callback(err)\n    } else {\n      // Multihashing inserts preamble of 2 bytes. Remove it.\n      // Also, murmur3 outputs 128 bit but, accidently, IPFS Go's\n      // implementation only uses the first 64, so we must do the same\n      // for parity..\n      const justHash = hash.slice(2, 10)\n      const length = justHash.length\n      const result = new Buffer(length)\n      // TODO: invert buffer because that's how Go impl does it\n      for (let i = 0; i < length; i++) {\n        result[length - i - 1] = justHash[i]\n      }\n      callback(null, result)\n    }\n  })\n}\nhashFn.code = 0x22 // TODO: get this from multihashing-async?\n\nconst defaultOptions = {\n  hashFn: hashFn\n}\n\nclass DirSharded extends Dir {\n  constructor (props, _options) {\n    super()\n    const options = Object.assign({}, defaultOptions, _options)\n    this._options = options\n    this._bucket = Bucket(options)\n    Object.assign(this, props)\n  }\n\n  put (name, value, callback) {\n    this._bucket.put(name, value, callback)\n  }\n\n  get (name, callback) {\n    this._bucket.get(name, callback)\n  }\n\n  childCount () {\n    return this._bucket.leafCount()\n  }\n\n  directChildrenCount () {\n    return this._bucket.childrenCount()\n  }\n\n  onlyChild (callback) {\n    this._bucket.onlyChild(callback)\n  }\n\n  eachChildSeries (iterator, callback) {\n    this._bucket.eachLeafSeries(iterator, callback)\n  }\n\n  flush (path, ipldResolver, source, callback) {\n    flush(this._options, this._bucket, path, ipldResolver, source, (err, node) => {\n      if (err) {\n        callback(err)\n      } else {\n        this.multihash = node.multihash\n        this.size = node.size\n      }\n      callback(null, node)\n    })\n  }\n}\n\nmodule.exports = createDirSharded\n\nfunction createDirSharded (props) {\n  return new DirSharded(props)\n}\n\nfunction flush (options, bucket, path, ipldResolver, source, callback) {\n  const children = bucket._children // TODO: intromission\n  let index = 0\n  const links = []\n  whilst(\n    () => index < children.length,\n    (callback) => {\n      const child = children.get(index)\n      if (child) {\n        collectChild(child, index, (err) => {\n          index++\n          callback(err)\n        })\n      } else {\n        index++\n        callback()\n      }\n    },\n    (err) => {\n      if (err) {\n        callback(err)\n        return // early\n      }\n      haveLinks(links)\n    }\n  )\n\n  function collectChild (child, index, callback) {\n    const labelPrefix = leftPad(index.toString(16).toUpperCase(), 2, '0')\n    if (Bucket.isBucket(child)) {\n      flush(options, child, path, ipldResolver, null, (err, node) => {\n        if (err) {\n          callback(err)\n          return // early\n        }\n        links.push(new DAGLink(labelPrefix, node.size, node.multihash))\n        callback()\n      })\n    } else {\n      const value = child.value\n      const label = labelPrefix + child.key\n      links.push(new DAGLink(label, value.size, value.multihash))\n      callback()\n    }\n  }\n\n  function haveLinks (links) {\n    // go-ipfs uses little endian, that's why we have to\n    // reverse the bit field before storing it\n    const data = new Buffer(children.bitField().reverse())\n    const dir = new UnixFS('hamt-sharded-directory', data)\n    dir.fanout = bucket.tableSize()\n    dir.hashType = options.hashFn.code\n    waterfall(\n      [\n        (callback) => DAGNode.create(dir.marshal(), links, callback),\n        (node, callback) => {\n          ipldResolver.put(\n            node,\n            {\n              cid: new CID(node.multihash)\n            },\n            (err) => callback(err, node))\n        },\n        (node, callback) => {\n          const pushable = {\n            path: path,\n            multihash: node.multihash,\n            size: node.size\n          }\n          if (source) {\n            source.push(pushable)\n          }\n          callback(null, node)\n        }\n      ],\n      callback)\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs-unixfs-engine/src/hamt/index.js":"'use strict'\n\nconst Bucket = require('./bucket')\n\nmodule.exports = function createHAMT (options) {\n  return new Bucket(options)\n}\n\nmodule.exports.isBucket = Bucket.isBucket\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs-unixfs-engine/src/hamt/bucket.js":"'use strict'\n\nconst SparseArray = require('sparse-array')\nconst map = require('async/map')\nconst eachSeries = require('async/eachSeries')\nconst wrapHash = require('./consumable-hash')\n\nconst defaultOptions = {\n  bits: 8\n}\n\n// TODO: make HAMT a generic NPM package\n\nclass Bucket {\n  constructor (options, parent, posAtParent) {\n    this._options = Object.assign({}, defaultOptions, options)\n    this._popCount = 0\n    this._parent = parent\n    this._posAtParent = posAtParent\n\n    if (!this._options.hashFn) {\n      throw new Error('please define an options.hashFn')\n    }\n\n    // make sure we only wrap options.hashFn once in the whole tree\n    if (!this._options.hash) {\n      this._options.hash = wrapHash(this._options.hashFn)\n    }\n    this._children = new SparseArray()\n  }\n\n  static isBucket (o) {\n    return o instanceof Bucket\n  }\n\n  put (key, value, callback) {\n    this._findNewBucketAndPos(key, (err, place) => {\n      if (err) {\n        callback(err)\n        return // early\n      }\n\n      place.bucket._putAt(place, key, value)\n      callback()\n    })\n  }\n\n  get (key, callback) {\n    this._findChild(key, (err, child) => {\n      if (err) {\n        callback(err)\n      } else {\n        callback(null, child && child.value)\n      }\n    })\n  }\n\n  del (key, callback) {\n    this._findPlace(key, (err, place) => {\n      if (err) {\n        callback(err)\n        return // early\n      }\n      const child = place.bucket._at(place.pos)\n      if (child && child.key === key) {\n        place.bucket._delAt(place.pos)\n      }\n      callback(null)\n    })\n  }\n\n  leafCount () {\n    this._children.reduce((acc, child) => {\n      if (child instanceof Bucket) {\n        return acc + child.leafCount()\n      }\n      return acc + 1\n    }, 0)\n  }\n\n  childrenCount () {\n    return this._children.length\n  }\n\n  onlyChild (callback) {\n    process.nextTick(() => callback(null, this._children.get(0)))\n  }\n\n  eachLeafSeries (iterator, callback) {\n    eachSeries(\n      this._children.compactArray(),\n      (child, cb) => {\n        if (child instanceof Bucket) {\n          child.eachLeafSeries(iterator, cb)\n        } else {\n          iterator(child.key, child.value, cb)\n        }\n      },\n      callback)\n  }\n\n  serialize (map, reduce) {\n    // serialize to a custom non-sparse representation\n    return reduce(this._children.reduce((acc, child, index) => {\n      if (child) {\n        if (child instanceof Bucket) {\n          acc.push(child.serialize(map, reduce))\n        } else {\n          acc.push(map(child, index))\n        }\n      }\n      return acc\n    }, []))\n  }\n\n  asyncTransform (asyncMap, asyncReduce, callback) {\n    asyncTransformBucket(this, asyncMap, asyncReduce, callback)\n  }\n\n  toJSON () {\n    return this.serialize(mapNode, reduceNodes)\n  }\n\n  prettyPrint () {\n    return JSON.stringify(this.toJSON(), null, '  ')\n  }\n\n  tableSize () {\n    return Math.pow(2, this._options.bits)\n  }\n\n  _findChild (key, callback) {\n    this._findPlace(key, (err, result) => {\n      if (err) {\n        callback(err)\n        return // early\n      }\n\n      const child = result.bucket._at(result.pos)\n      if (child && child.key === key) {\n        callback(null, child)\n      } else {\n        callback(null, undefined)\n      }\n    })\n  }\n\n  _findPlace (key, callback) {\n    const hashValue = this._options.hash(key)\n    hashValue.take(this._options.bits, (err, index) => {\n      if (err) {\n        callback(err)\n        return // early\n      }\n\n      const child = this._children.get(index)\n      if (child instanceof Bucket) {\n        child._findPlace(hashValue, callback)\n      } else {\n        const place = {\n          bucket: this,\n          pos: index,\n          hash: hashValue\n        }\n        callback(null, place)\n      }\n    })\n  }\n\n  _findNewBucketAndPos (key, callback) {\n    this._findPlace(key, (err, place) => {\n      if (err) {\n        callback(err)\n        return // early\n      }\n      const child = place.bucket._at(place.pos)\n      if (child && child.key !== key) {\n        // conflict\n\n        const bucket = new Bucket(this._options, place.bucket, place.pos)\n        place.bucket._putObjectAt(place.pos, bucket)\n\n        // put the previous value\n        bucket._findPlace(child.hash, (err, newPlace) => {\n          if (err) {\n            callback(err)\n            return // early\n          }\n\n          newPlace.bucket._putAt(newPlace, child.key, child.value)\n          bucket._findNewBucketAndPos(place.hash, callback)\n        })\n      } else {\n        // no conflict, we found the place\n        callback(null, place)\n      }\n    })\n  }\n\n  _putAt (place, key, value) {\n    this._putObjectAt(place.pos, {\n      key: key,\n      value: value,\n      hash: place.hash\n    })\n  }\n\n  _putObjectAt (pos, object) {\n    if (!this._children.get(pos)) {\n      this._popCount++\n    }\n    this._children.set(pos, object)\n  }\n\n  _delAt (pos) {\n    if (this._children.get(pos)) {\n      this._popCount--\n    }\n    this._children.unset(pos)\n    this._level()\n  }\n\n  _level () {\n    if (this._parent && this._popCount <= 1) {\n      if (this._popCount === 1) {\n        // remove myself from parent, replacing me with my only child\n        const onlyChild = this._children.find(exists)\n        if (!(onlyChild instanceof Bucket)) {\n          const hash = onlyChild.hash\n          hash.untake(this._options.bits)\n          const place = {\n            pos: this._posAtParent,\n            hash: hash\n          }\n          this._parent._putAt(place, onlyChild.key, onlyChild.value)\n        }\n      } else {\n        this._parent._delAt(this._posAtParent)\n      }\n    }\n  }\n\n  _at (index) {\n    return this._children.get(index)\n  }\n}\n\nfunction exists (o) {\n  return Boolean(o)\n}\n\nfunction mapNode (node, index) {\n  return node.key\n}\n\nfunction reduceNodes (nodes) {\n  return nodes\n}\n\nfunction asyncTransformBucket (bucket, asyncMap, asyncReduce, callback) {\n  map(\n    bucket._children.compactArray(),\n    (child, callback) => {\n      if (child instanceof Bucket) {\n        asyncTransformBucket(child, asyncMap, asyncReduce, callback)\n      } else {\n        asyncMap(child, (err, mappedChildren) => {\n          if (err) {\n            callback(err)\n          } else {\n            callback(null, {\n              bitField: bucket._children.bitField(),\n              children: mappedChildren\n            })\n          }\n        })\n      }\n    },\n    (err, mappedChildren) => {\n      if (err) {\n        callback(err)\n      } else {\n        asyncReduce(mappedChildren, callback)\n      }\n    }\n  )\n}\n\nmodule.exports = Bucket\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs-unixfs-engine/src/hamt/consumable-hash.js":"'use strict'\n\nconst whilst = require('async/whilst')\nconst ConsumableBuffer = require('./consumable-buffer')\n\nmodule.exports = function wrapHash (hashFn) {\n  return function hashing (value) {\n    if (value instanceof InfiniteHash) {\n      // already a hash. return it\n      return value\n    } else {\n      return new InfiniteHash(value, hashFn)\n    }\n  }\n}\n\nclass InfiniteHash {\n  constructor (value, hashFn) {\n    if ((typeof value) !== 'string' && !Buffer.isBuffer(value)) {\n      throw new Error('can only hash strings or buffers')\n    }\n    this._value = value\n    this._hashFn = hashFn\n    this._depth = -1\n    this._availableBits = 0\n    this._currentBufferIndex = 0\n    this._buffers = []\n  }\n\n  take (bits, callback) {\n    let pendingBits = bits\n    whilst(\n      () => this._availableBits < pendingBits,\n      (callback) => {\n        this._produceMoreBits(callback)\n      },\n      (err) => {\n        if (err) {\n          callback(err)\n          return // early\n        }\n\n        let result = 0\n\n        // TODO: this is sync, no need to use whilst\n        whilst(\n          () => pendingBits > 0,\n          (callback) => {\n            const hash = this._buffers[this._currentBufferIndex]\n            const available = Math.min(hash.availableBits(), pendingBits)\n            const took = hash.take(available)\n            result = (result << available) + took\n            pendingBits -= available\n            this._availableBits -= available\n            if (hash.availableBits() === 0) {\n              this._currentBufferIndex++\n            }\n            callback()\n          },\n          (err) => {\n            if (err) {\n              callback(err)\n              return // early\n            }\n\n            process.nextTick(() => callback(null, result))\n          }\n        )\n      }\n    )\n  }\n\n  untake (bits) {\n    let pendingBits = bits\n    while (pendingBits > 0) {\n      const hash = this._buffers[this._currentBufferIndex]\n      const availableForUntake = Math.min(hash.totalBits() - hash.availableBits(), pendingBits)\n      hash.untake(availableForUntake)\n      pendingBits -= availableForUntake\n      this._availableBits += availableForUntake\n      if (this._currentBufferIndex > 0 && hash.totalBits() === hash.availableBits()) {\n        this._depth--\n        this._currentBufferIndex--\n      }\n    }\n  }\n\n  _produceMoreBits (callback) {\n    this._depth++\n    const value = this._depth ? this._value + this._depth : this._value\n    this._hashFn(value, (err, hashValue) => {\n      if (err) {\n        callback(err)\n        return // early\n      }\n\n      const buffer = new ConsumableBuffer(hashValue)\n      this._buffers.push(buffer)\n      this._availableBits += buffer.availableBits()\n      callback()\n    })\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs-unixfs-engine/src/hamt/consumable-buffer.js":"'use strict'\n\nconst START_MASKS = [\n  0b11111111,\n  0b11111110,\n  0b11111100,\n  0b11111000,\n  0b11110000,\n  0b11100000,\n  0b11000000,\n  0b10000000\n]\n\nconst STOP_MASKS = [\n  0b00000001,\n  0b00000011,\n  0b00000111,\n  0b00001111,\n  0b00011111,\n  0b00111111,\n  0b01111111,\n  0b11111111\n]\n\nmodule.exports = class ConsumableBuffer {\n  constructor (value) {\n    this._value = value\n    this._currentBytePos = value.length - 1\n    this._currentBitPos = 7\n  }\n\n  availableBits () {\n    return this._currentBitPos + 1 + this._currentBytePos * 8\n  }\n\n  totalBits () {\n    return this._value.length * 8\n  }\n\n  take (bits) {\n    let pendingBits = bits\n    let result = 0\n    while (pendingBits && this._haveBits()) {\n      const byte = this._value[this._currentBytePos]\n      const availableBits = this._currentBitPos + 1\n      const taking = Math.min(availableBits, pendingBits)\n      const value = byteBitsToInt(byte, availableBits - taking, taking)\n      result = (result << taking) + value\n\n      pendingBits -= taking\n\n      this._currentBitPos -= taking\n      if (this._currentBitPos < 0) {\n        this._currentBitPos = 7\n        this._currentBytePos --\n      }\n    }\n\n    return result\n  }\n\n  untake (bits) {\n    this._currentBitPos += bits\n    while (this._currentBitPos > 7) {\n      this._currentBitPos -= 8\n      this._currentBytePos += 1\n    }\n  }\n\n  _haveBits () {\n    return this._currentBytePos >= 0\n  }\n}\n\nfunction byteBitsToInt (byte, start, length) {\n  const mask = maskFor(start, length)\n  return (byte & mask) >>> start\n}\n\nfunction maskFor (start, length) {\n  return START_MASKS[start] & STOP_MASKS[Math.min(length + start - 1, 7)]\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs-unixfs-engine/src/chunker/fixed-size.js":"'use strict'\n\nconst pullBlock = require('pull-block')\n\nmodule.exports = (options) => {\n  let maxSize = (typeof options === 'number') ? options : options.maxChunkSize\n  return pullBlock(maxSize, { zeroPadding: false, emitEmpty: true })\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs-unixfs-engine/src/exporter/index.js":"'use strict'\n\nconst pull = require('pull-stream')\nconst CID = require('cids')\nconst isIPFS = require('is-ipfs')\n\nconst resolve = require('./resolve').resolve\nconst cleanMultihash = require('./clean-multihash')\n\nmodule.exports = (hash, ipldResolver) => {\n  if (!isIPFS.multihash(hash)) {\n    return pull.error(new Error('not valid multihash'))\n  }\n\n  hash = cleanMultihash(hash)\n\n  return pull(\n    ipldResolver.getStream(new CID(hash)),\n    pull.map((result) => result.value),\n    pull.map((node) => resolve(node, hash, ipldResolver)),\n    pull.flatten()\n  )\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs-unixfs-engine/src/exporter/resolve.js":"'use strict'\n\nconst UnixFS = require('ipfs-unixfs')\nconst pull = require('pull-stream')\n\nconst resolvers = {\n  directory: require('./dir-flat'),\n  'hamt-sharded-directory': require('./dir-hamt-sharded'),\n  file: require('./file')\n}\n\nmodule.exports = Object.assign({\n  resolve: resolve,\n  typeOf: typeOf\n}, resolvers)\n\nfunction resolve (node, name, ipldResolver, parentNode) {\n  const type = typeOf(node)\n  const resolver = resolvers[type]\n  if (!resolver) {\n    return pull.error(new Error('Unkown node type ' + type))\n  }\n  let stream = resolver(node, name, ipldResolver, resolve, parentNode)\n  return stream\n}\n\nfunction typeOf (node) {\n  const data = UnixFS.unmarshal(node.data)\n  return data.type\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs-unixfs-engine/src/exporter/dir-flat.js":"'use strict'\n\nconst path = require('path')\nconst pull = require('pull-stream')\nconst paramap = require('pull-paramap')\nconst CID = require('cids')\nconst cat = require('pull-cat')\n\n// Logic to export a unixfs directory.\nmodule.exports = dirExporter\n\nfunction dirExporter (node, name, ipldResolver, resolve, parent) {\n  const dir = {\n    path: name,\n    hash: node.multihash\n  }\n\n  return cat([\n    pull.values([dir]),\n    pull(\n      pull.values(node.links),\n      pull.map((link) => ({\n        path: path.join(name, link.name),\n        hash: link.multihash\n      })),\n      paramap((item, cb) => ipldResolver.get(new CID(item.hash), (err, n) => {\n        if (err) {\n          return cb(err)\n        }\n\n        cb(null, resolve(n.value, item.path, ipldResolver, name, parent))\n      })),\n      pull.flatten()\n    )\n  ])\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs-unixfs-engine/src/exporter/dir-hamt-sharded.js":"'use strict'\n\nconst path = require('path')\nconst pull = require('pull-stream')\nconst paramap = require('pull-paramap')\nconst CID = require('cids')\nconst cat = require('pull-cat')\nconst cleanHash = require('./clean-multihash')\n\n// Logic to export a unixfs directory.\nmodule.exports = shardedDirExporter\n\nfunction shardedDirExporter (node, name, ipldResolver, resolve, parent) {\n  let dir\n  if (!parent || parent.path !== name) {\n    dir = [{\n      path: name,\n      hash: cleanHash(node.multihash)\n    }]\n  }\n\n  return cat([\n    pull.values(dir),\n    pull(\n      pull.values(node.links),\n      pull.map((link) => {\n        // remove the link prefix (2 chars for the bucket index)\n        let p = link.name.substring(2)\n        // another sharded dir or file?\n        p = p ? path.join(name, p) : name\n\n        return {\n          name: link.name,\n          path: p,\n          hash: link.multihash\n        }\n      }),\n      paramap((item, cb) => ipldResolver.get(new CID(item.hash), (err, n) => {\n        if (err) {\n          return cb(err)\n        }\n\n        cb(null, resolve(n.value, item.path, ipldResolver, (dir && dir[0]) || parent))\n      })),\n      pull.flatten()\n    )\n  ])\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs-unixfs-engine/src/exporter/clean-multihash.js":"'use strict'\n\nconst mh = require('multihashes')\n\nmodule.exports = (multihash) => {\n  if (Buffer.isBuffer(multihash)) {\n    return mh.toB58String(multihash)\n  }\n\n  return multihash\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs-unixfs-engine/src/exporter/file.js":"'use strict'\n\nconst traverse = require('pull-traverse')\nconst UnixFS = require('ipfs-unixfs')\nconst CID = require('cids')\nconst pull = require('pull-stream')\nconst paramap = require('pull-paramap')\n\n// Logic to export a single (possibly chunked) unixfs file.\nmodule.exports = (node, name, ipldResolver) => {\n  function getData (node) {\n    try {\n      const file = UnixFS.unmarshal(node.data)\n      return file.data || new Buffer(0)\n    } catch (err) {\n      throw new Error('Failed to unmarshal node')\n    }\n  }\n\n  function visitor (node) {\n    return pull(\n      pull.values(node.links),\n      paramap((link, cb) => ipldResolver.get(new CID(link.multihash), cb)),\n      pull.map((result) => result.value)\n    )\n  }\n\n  let content = pull(\n    traverse.depthFirst(node, visitor),\n    pull.map(getData)\n  )\n\n  const file = UnixFS.unmarshal(node.data)\n  return pull.values([{\n    content: content,\n    path: name,\n    size: file.fileSize()\n  }])\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs/src/core/components/bootstrap.js":"'use strict'\n\nconst isNode = require('detect-node')\n\nconst defaultNodes = isNode\n  ? require('../../init-files/default-config-node.json').Bootstrap\n  : require('../../init-files/default-config-browser.json').Bootstrap\n\nmodule.exports = function bootstrap (self) {\n  return {\n    list: (callback) => {\n      self._repo.config.get((err, config) => {\n        if (err) {\n          return callback(err)\n        }\n        callback(null, {Peers: config.Bootstrap})\n      })\n    },\n    add: (multiaddr, args, callback) => {\n      if (typeof args === 'function') {\n        callback = args\n        args = {default: false}\n      }\n      self._repo.config.get((err, config) => {\n        if (err) {\n          return callback(err)\n        }\n        if (args.default) {\n          config.Bootstrap = defaultNodes\n        } else if (multiaddr) {\n          config.Bootstrap.push(multiaddr)\n        }\n        self._repo.config.set(config, (err) => {\n          if (err) {\n            return callback(err)\n          }\n\n          callback(null, {\n            Peers: args.default ? defaultNodes : [multiaddr]\n          })\n        })\n      })\n    },\n    rm: (multiaddr, args, callback) => {\n      if (typeof args === 'function') {\n        callback = args\n        args = {all: false}\n      }\n      self._repo.config.get((err, config) => {\n        if (err) {\n          return callback(err)\n        }\n        if (args.all) {\n          config.Bootstrap = []\n        } else {\n          config.Bootstrap = config.Bootstrap.filter((mh) => mh !== multiaddr)\n        }\n\n        self._repo.config.set(config, (err) => {\n          if (err) {\n            return callback(err)\n          }\n\n          const res = []\n          if (!args.all && multiaddr) {\n            res.push(multiaddr)\n          }\n\n          callback(null, {Peers: res})\n        })\n      })\n    }\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs/src/core/components/config.js":"'use strict'\n\nconst promisify = require('promisify-es6')\nconst _get = require('lodash.get')\nconst _has = require('lodash.has')\nconst _set = require('lodash.set')\n\nmodule.exports = function config (self) {\n  return {\n    get: promisify((key, callback) => {\n      if (typeof key === 'function') {\n        callback = key\n        key = undefined\n      }\n\n      if (!key) {\n        return self._repo.config.get(callback)\n      }\n\n      if (typeof key !== 'string') {\n        return callback(new Error('Invalid key type'))\n      }\n\n      self._repo.config.get((err, config) => {\n        if (err) {\n          return callback(err)\n        }\n        if (_has(config, key)) {\n          const value = _get(config, key, undefined)\n          callback(null, value)\n        } else {\n          callback(new Error('Key does not exist in config'))\n        }\n      })\n    }),\n    set: promisify((key, value, callback) => {\n      if (!key || typeof key !== 'string') {\n        return callback(new Error('Invalid key type'))\n      }\n\n      if (value === undefined || Buffer.isBuffer(value)) {\n        return callback(new Error('Invalid value type'))\n      }\n\n      self._repo.config.get((err, config) => {\n        if (err) {\n          return callback(err)\n        }\n        _set(config, key, value)\n        self.config.replace(config, callback)\n      })\n    }),\n    replace: promisify((config, callback) => {\n      self._repo.config.set(config, callback)\n    })\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs/src/core/components/block.js":"'use strict'\n\nconst Block = require('ipfs-block')\nconst multihash = require('multihashes')\nconst multihashing = require('multihashing-async')\nconst CID = require('cids')\nconst waterfall = require('async/waterfall')\n\nmodule.exports = function block (self) {\n  return {\n    get: (cid, callback) => {\n      cid = cleanCid(cid)\n      self._blockService.get(cid, callback)\n    },\n    put: (block, callback) => {\n      if (Array.isArray(block)) {\n        return callback(new Error('Array is not supported'))\n      }\n\n      waterfall([\n        (cb) => {\n          if (Block.isBlock(block)) {\n            return cb(null, block)\n          }\n\n          multihashing(block, 'sha2-256', (err, multihash) => {\n            if (err) {\n              return cb(err)\n            }\n\n            cb(null, new Block(block, new CID(multihash)))\n          })\n        },\n        (block, cb) => self._blockService.put(block, (err) => {\n          if (err) {\n            return cb(err)\n          }\n          cb(null, block)\n        })\n      ], callback)\n    },\n    rm: (cid, callback) => {\n      cid = cleanCid(cid)\n      self._blockService.delete(cid, callback)\n    },\n    stat: (cid, callback) => {\n      cid = cleanCid(cid)\n\n      self._blockService.get(cid, (err, block) => {\n        if (err) {\n          return callback(err)\n        }\n        callback(null, {\n          key: multihash.toB58String(cid.multihash),\n          size: block.data.length\n        })\n      })\n    }\n  }\n}\n\nfunction cleanCid (cid) {\n  if (CID.isCID(cid)) {\n    return cid\n  }\n\n  // CID constructor knows how to do the cleaning :)\n  return new CID(cid)\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs/src/core/components/object.js":"'use strict'\n\nconst waterfall = require('async/waterfall')\nconst promisify = require('promisify-es6')\nconst dagPB = require('ipld-dag-pb')\nconst DAGNode = dagPB.DAGNode\nconst DAGLink = dagPB.DAGLink\nconst CID = require('cids')\nconst mh = require('multihashes')\nconst Unixfs = require('ipfs-unixfs')\nconst assert = require('assert')\n\nfunction normalizeMultihash (multihash, enc) {\n  if (typeof multihash === 'string') {\n    if (enc === 'base58') {\n      return multihash\n    }\n\n    return new Buffer(multihash, enc)\n  } else if (Buffer.isBuffer(multihash)) {\n    return multihash\n  } else {\n    throw new Error('unsupported multihash')\n  }\n}\n\nfunction parseBuffer (buf, encoding, callback) {\n  switch (encoding) {\n    case 'json':\n      return parseJSONBuffer(buf, callback)\n    case 'protobuf':\n      return parseProtoBuffer(buf, callback)\n    default:\n      callback(new Error(`unkown encoding: ${encoding}`))\n  }\n}\n\nfunction parseJSONBuffer (buf, callback) {\n  let data\n  let links\n\n  try {\n    const parsed = JSON.parse(buf.toString())\n\n    links = (parsed.Links || []).map((link) => {\n      return new DAGLink(\n        link.Name || link.name,\n        link.Size || link.size,\n        mh.fromB58String(link.Hash || link.hash || link.multihash)\n      )\n    })\n    data = new Buffer(parsed.Data)\n  } catch (err) {\n    return callback(new Error('failed to parse JSON: ' + err))\n  }\n\n  DAGNode.create(data, links, callback)\n}\n\nfunction parseProtoBuffer (buf, callback) {\n  dagPB.util.deserialize(buf, callback)\n}\n\nmodule.exports = function object (self) {\n  function editAndSave (edit) {\n    return (multihash, options, callback) => {\n      if (typeof options === 'function') {\n        callback = options\n        options = {}\n      }\n\n      waterfall([\n        (cb) => {\n          self.object.get(multihash, options, cb)\n        },\n        (node, cb) => {\n          // edit applies the edit func passed to\n          // editAndSave\n          edit(node, (err, node) => {\n            if (err) {\n              return cb(err)\n            }\n            self._ipldResolver.put(node, {\n              cid: new CID(node.multihash)\n            }, (err) => {\n              cb(err, node)\n            })\n          })\n        }\n      ], callback)\n    }\n  }\n\n  return {\n    new: promisify((template, callback) => {\n      if (typeof template === 'function') {\n        callback = template\n        template = undefined\n      }\n\n      let data\n\n      if (template) {\n        assert(template === 'unixfs-dir', 'unkown template')\n        data = (new Unixfs('directory')).marshal()\n      } else {\n        data = new Buffer(0)\n      }\n\n      DAGNode.create(data, (err, node) => {\n        if (err) {\n          return callback(err)\n        }\n        self._ipldResolver.put(node, {\n          cid: new CID(node.multihash)\n        }, (err) => {\n          if (err) {\n            return callback(err)\n          }\n\n          callback(null, node)\n        })\n      })\n    }),\n    put: promisify((obj, options, callback) => {\n      if (typeof options === 'function') {\n        callback = options\n        options = {}\n      }\n\n      const encoding = options.enc\n      let node\n\n      if (Buffer.isBuffer(obj)) {\n        if (encoding) {\n          parseBuffer(obj, encoding, (err, _node) => {\n            if (err) {\n              return callback(err)\n            }\n            node = _node\n            next()\n          })\n        } else {\n          DAGNode.create(obj, (err, _node) => {\n            if (err) {\n              return callback(err)\n            }\n            node = _node\n            next()\n          })\n        }\n      } else if (obj.multihash) {\n        // already a dag node\n        node = obj\n        next()\n      } else if (typeof obj === 'object') {\n        DAGNode.create(obj.Data, obj.Links, (err, _node) => {\n          if (err) {\n            return callback(err)\n          }\n          node = _node\n          next()\n        })\n      } else {\n        return callback(new Error('obj not recognized'))\n      }\n\n      function next () {\n        self._ipldResolver.put(node, {\n          cid: new CID(node.multihash)\n        }, (err) => {\n          if (err) {\n            return callback(err)\n          }\n\n          self.object.get(node.multihash, callback)\n        })\n      }\n    }),\n\n    get: promisify((multihash, options, callback) => {\n      if (typeof options === 'function') {\n        callback = options\n        options = {}\n      }\n\n      let mh\n\n      try {\n        mh = normalizeMultihash(multihash, options.enc)\n      } catch (err) {\n        return callback(err)\n      }\n      const cid = new CID(mh)\n\n      self._ipldResolver.get(cid, (err, result) => {\n        if (err) {\n          return callback(err)\n        }\n\n        const node = result.value\n\n        callback(null, node)\n      })\n    }),\n\n    data: promisify((multihash, options, callback) => {\n      if (typeof options === 'function') {\n        callback = options\n        options = {}\n      }\n\n      self.object.get(multihash, options, (err, node) => {\n        if (err) {\n          return callback(err)\n        }\n        callback(null, node.data)\n      })\n    }),\n\n    links: promisify((multihash, options, callback) => {\n      if (typeof options === 'function') {\n        callback = options\n        options = {}\n      }\n\n      self.object.get(multihash, options, (err, node) => {\n        if (err) {\n          return callback(err)\n        }\n\n        callback(null, node.links)\n      })\n    }),\n\n    stat: promisify((multihash, options, callback) => {\n      if (typeof options === 'function') {\n        callback = options\n        options = {}\n      }\n\n      self.object.get(multihash, options, (err, node) => {\n        if (err) {\n          return callback(err)\n        }\n\n        dagPB.util.serialize(node, (err, serialized) => {\n          if (err) {\n            return callback(err)\n          }\n\n          const blockSize = serialized.length\n          const linkLength = node.links.reduce((a, l) => a + l.size, 0)\n\n          const nodeJSON = node.toJSON()\n\n          callback(null, {\n            Hash: nodeJSON.multihash,\n            NumLinks: node.links.length,\n            BlockSize: blockSize,\n            LinksSize: blockSize - node.data.length,\n            DataSize: node.data.length,\n            CumulativeSize: blockSize + linkLength\n          })\n        })\n      })\n    }),\n\n    patch: promisify({\n      addLink (multihash, link, options, callback) {\n        editAndSave((node, cb) => {\n          DAGNode.addLink(node, link, cb)\n        })(multihash, options, callback)\n      },\n\n      rmLink (multihash, linkRef, options, callback) {\n        editAndSave((node, cb) => {\n          if (linkRef.constructor &&\n              linkRef.constructor.name === 'DAGLink') {\n            linkRef = linkRef._name\n          }\n          DAGNode.rmLink(node, linkRef, cb)\n        })(multihash, options, callback)\n      },\n\n      appendData (multihash, data, options, callback) {\n        editAndSave((node, cb) => {\n          const newData = Buffer.concat([node.data, data])\n          DAGNode.create(newData, node.links, cb)\n        })(multihash, options, callback)\n      },\n\n      setData (multihash, data, options, callback) {\n        editAndSave((node, cb) => {\n          DAGNode.create(data, node.links, cb)\n        })(multihash, options, callback)\n      }\n    })\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs/src/core/components/dag.js":"'use strict'\n\nconst promisify = require('promisify-es6')\nconst CID = require('cids')\nconst pull = require('pull-stream')\n\nmodule.exports = function dag (self) {\n  return {\n    put: promisify((dagNode, options, callback) => {\n      self._ipldResolver.put(dagNode, options, callback)\n    }),\n\n    get: promisify((cid, path, options, callback) => {\n      if (typeof path === 'function') {\n        callback = path\n        path = undefined\n      }\n\n      if (typeof options === 'function') {\n        callback = options\n        options = {}\n      }\n\n      options = options || {}\n\n      if (typeof cid === 'string') {\n        const split = cid.split('/')\n        cid = new CID(split[0])\n        split.shift()\n\n        if (split.length > 0) {\n          path = split.join('/')\n        } else {\n          path = '/'\n        }\n      }\n\n      self._ipldResolver.get(cid, path, options, callback)\n    }),\n\n    tree: promisify((cid, path, options, callback) => {\n      if (typeof path === 'object') {\n        callback = options\n        options = path\n        path = undefined\n      }\n\n      if (typeof path === 'function') {\n        callback = path\n        path = undefined\n      }\n\n      if (typeof options === 'function') {\n        callback = options\n        options = {}\n      }\n\n      options = options || {}\n\n      if (typeof cid === 'string') {\n        const split = cid.split('/')\n        cid = new CID(split[0])\n        split.shift()\n\n        if (split.length > 0) {\n          path = split.join('/')\n        } else {\n          path = undefined\n        }\n      }\n\n      pull(\n        self._ipldResolver.treeStream(cid, path, options),\n        pull.collect(callback)\n      )\n    })\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs/src/core/components/libp2p.js":"'use strict'\n\nconst Node = require('libp2p-ipfs-nodejs')\nconst promisify = require('promisify-es6')\nconst get = require('lodash.get')\n\nmodule.exports = function libp2p (self) {\n  return {\n    start: promisify((callback) => {\n      self.config.get(gotConfig)\n\n      function gotConfig (err, config) {\n        if (err) {\n          return callback(err)\n        }\n\n        const options = {\n          mdns: get(config, 'Discovery.MDNS.Enabled'),\n          webRTCStar: get(config, 'Discovery.webRTCStar.Enabled'),\n          bootstrap: get(config, 'Bootstrap')\n        }\n\n        self._libp2pNode = new Node(self._peerInfo, self._peerInfoBook, options)\n\n        self._libp2pNode.start((err) => {\n          if (err) {\n            return callback(err)\n          }\n\n          self._libp2pNode.peerInfo.multiaddrs.forEach((ma) => {\n            console.log('Swarm listening on', ma.toString())\n          })\n\n          self._libp2pNode.discovery.on('peer', (peerInfo) => {\n            if (self.isOnline()) {\n              self._peerInfoBook.put(peerInfo)\n              self._libp2pNode.dialByPeerInfo(peerInfo, () => {})\n            }\n          })\n          self._libp2pNode.swarm.on('peer-mux-established', (peerInfo) => {\n            self._peerInfoBook.put(peerInfo)\n          })\n\n          callback()\n        })\n      }\n    }),\n    stop: promisify((callback) => {\n      self._libp2pNode.stop(callback)\n    })\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs/src/core/components/swarm.js":"'use strict'\n\nconst multiaddr = require('multiaddr')\nconst promisify = require('promisify-es6')\nconst flatMap = require('lodash.flatmap')\nconst values = require('lodash.values')\n\nconst OFFLINE_ERROR = require('../utils').OFFLINE_ERROR\n\nmodule.exports = function swarm (self) {\n  return {\n    peers: promisify((opts, callback) => {\n      if (typeof opts === 'function') {\n        callback = opts\n        opts = {}\n      }\n\n      if (!self.isOnline()) {\n        return callback(OFFLINE_ERROR)\n      }\n\n      const verbose = opts.v || opts.verbose\n      // TODO: return latency and streams when verbose is set\n      // we currently don't have this information\n\n      const peers = self._peerInfoBook.getAll()\n      const keys = Object.keys(peers)\n\n      const peerList = flatMap(keys, (id) => {\n        const peer = peers[id]\n\n        return peer.multiaddrs.map((addr) => {\n          const res = {\n            addr: addr,\n            peer: peers[id]\n          }\n\n          if (verbose) {\n            res.latency = 'unknown'\n          }\n\n          return res\n        })\n      })\n\n      callback(null, peerList)\n    }),\n\n    // all the addrs we know\n    addrs: promisify((callback) => {\n      if (!self.isOnline()) {\n        return callback(OFFLINE_ERROR)\n      }\n\n      const peers = values(self._peerInfoBook.getAll())\n      callback(null, peers)\n    }),\n\n    localAddrs: promisify((callback) => {\n      if (!self.isOnline()) {\n        return callback(OFFLINE_ERROR)\n      }\n\n      callback(null, self._libp2pNode.peerInfo.multiaddrs)\n    }),\n\n    connect: promisify((maddr, callback) => {\n      if (!self.isOnline()) {\n        return callback(OFFLINE_ERROR)\n      }\n\n      if (typeof maddr === 'string') {\n        maddr = multiaddr(maddr)\n      }\n\n      self._libp2pNode.dialByMultiaddr(maddr, callback)\n    }),\n\n    disconnect: promisify((maddr, callback) => {\n      if (!self.isOnline()) {\n        return callback(OFFLINE_ERROR)\n      }\n\n      if (typeof maddr === 'string') {\n        maddr = multiaddr(maddr)\n      }\n\n      self._libp2pNode.hangUpByMultiaddr(maddr, callback)\n    }),\n\n    filters: promisify((callback) => {\n      // TODO\n      throw new Error('Not implemented')\n    })\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs/src/core/utils.js":"'use strict'\n\nexports.OFFLINE_ERROR = new Error('This command must be run in online mode. Try running \\'ipfs daemon\\' first.')\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs/src/core/components/ping.js":"'use strict'\n\nconst promisify = require('promisify-es6')\n\nmodule.exports = function ping (self) {\n  return promisify((callback) => {\n    callback(new Error('Not implemented'))\n  })\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs/src/core/components/files.js":"'use strict'\n\nconst unixfsEngine = require('ipfs-unixfs-engine')\nconst importer = unixfsEngine.importer\nconst exporter = unixfsEngine.exporter\nconst UnixFS = require('ipfs-unixfs')\nconst promisify = require('promisify-es6')\nconst multihashes = require('multihashes')\nconst pull = require('pull-stream')\nconst sort = require('pull-sort')\nconst pushable = require('pull-pushable')\nconst toStream = require('pull-stream-to-stream')\nconst toPull = require('stream-to-pull-stream')\nconst CID = require('cids')\nconst waterfall = require('async/waterfall')\nconst isStream = require('isstream')\nconst Duplex = require('stream').Duplex\n\nmodule.exports = function files (self) {\n  const createAddPullStream = (options) => {\n    return pull(\n      pull.map(normalizeContent),\n      pull.flatten(),\n      importer(self._ipldResolver, options),\n      pull.asyncMap(prepareFile.bind(null, self))\n    )\n  }\n\n  return {\n    createAddStream: (options, callback) => {\n      if (typeof options === 'function') {\n        callback = options\n        options = undefined\n      }\n\n      const addPullStream = createAddPullStream(options)\n      const p = pushable()\n      const s = pull(\n        p,\n        addPullStream\n      )\n\n      const retStream = new AddStreamDuplex(s, p)\n\n      retStream.once('finish', () => p.end())\n\n      callback(null, retStream)\n    },\n\n    createAddPullStream: createAddPullStream,\n\n    add: promisify((data, options, callback) => {\n      if (typeof options === 'function') {\n        callback = options\n        options = undefined\n      } else if (!callback || typeof callback !== 'function') {\n        callback = noop\n      }\n\n      if (typeof data !== 'object' &&\n          !Buffer.isBuffer(data) &&\n          !isStream(data)) {\n        return callback(new Error('Invalid arguments, data must be an object, Buffer or readable stream'))\n      }\n\n      pull(\n        pull.values(normalizeContent(data)),\n        importer(self._ipldResolver, options),\n        pull.asyncMap(prepareFile.bind(null, self)),\n        sort((a, b) => {\n          if (a.path < b.path) return 1\n          if (a.path > b.path) return -1\n          return 0\n        }),\n        pull.collect(callback)\n      )\n    }),\n\n    cat: promisify((hash, callback) => {\n      if (typeof hash === 'function') {\n        return callback(new Error('You must supply a multihash'))\n      }\n\n      self._ipldResolver.get(new CID(hash), (err, result) => {\n        if (err) {\n          return callback(err)\n        }\n\n        const node = result.value\n\n        const data = UnixFS.unmarshal(node.data)\n\n        if (data.type === 'directory') {\n          return callback(new Error('This dag node is a directory'))\n        }\n\n        pull(\n          exporter(hash, self._ipldResolver),\n          pull.collect((err, files) => {\n            if (err) {\n              return callback(err)\n            }\n            callback(null, toStream.source(files[0].content))\n          })\n        )\n      })\n    }),\n\n    get: promisify((hash, callback) => {\n      callback(null, toStream.source(pull(\n        exporter(hash, self._ipldResolver),\n        pull.map((file) => {\n          if (file.content) {\n            file.content = toStream.source(file.content)\n            file.content.pause()\n          }\n\n          return file\n        })\n      )))\n    }),\n\n    getPull: promisify((hash, callback) => {\n      callback(null, exporter(hash, self._ipldResolver))\n    })\n  }\n}\n\nfunction prepareFile (self, file, callback) {\n  const bs58mh = multihashes.toB58String(file.multihash)\n\n  waterfall([\n    (cb) => self.object.get(file.multihash, cb),\n    (node, cb) => {\n      cb(null, {\n        path: file.path || bs58mh,\n        hash: bs58mh,\n        size: node.size\n      })\n    }\n  ], callback)\n}\n\nfunction normalizeContent (content) {\n  if (!Array.isArray(content)) {\n    content = [content]\n  }\n\n  return content.map((data) => {\n    // Buffer input\n    if (Buffer.isBuffer(data)) {\n      data = {\n        path: '',\n        content: pull.values([data])\n      }\n    }\n\n    // Readable stream input\n    if (isStream.isReadable(data)) {\n      data = {\n        path: '',\n        content: toPull.source(data)\n      }\n    }\n\n    if (data && data.content && typeof data.content !== 'function') {\n      if (Buffer.isBuffer(data.content)) {\n        data.content = pull.values([data.content])\n      }\n\n      if (isStream.isReadable(data.content)) {\n        data.content = toPull.source(data.content)\n      }\n    }\n\n    return data\n  })\n}\n\nfunction noop () {}\n\nclass AddStreamDuplex extends Duplex {\n  constructor (pullStream, push, options) {\n    super(Object.assign({ objectMode: true }, options))\n    this._pullStream = pullStream\n    this._pushable = push\n    this._waitingPullFlush = []\n  }\n\n  _read () {\n    this._pullStream(null, (end, data) => {\n      while (this._waitingPullFlush.length) {\n        const cb = this._waitingPullFlush.shift()\n        cb()\n      }\n      if (end) {\n        if (end instanceof Error) {\n          this.emit('error', end)\n        }\n      } else {\n        this.push(data)\n      }\n    })\n  }\n\n  _write (chunk, encoding, callback) {\n    this._waitingPullFlush.push(callback)\n    this._pushable.push(chunk)\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs/src/core/components/bitswap.js":"'use strict'\n\nconst OFFLINE_ERROR = require('../utils').OFFLINE_ERROR\n\nfunction formatWantlist (list) {\n  return Array.from(list).map((e) => e[1])\n}\n\nmodule.exports = function bitswap (self) {\n  return {\n    wantlist: () => {\n      if (!self.isOnline()) {\n        throw OFFLINE_ERROR\n      }\n\n      const list = self._bitswap.getWantlist()\n      return formatWantlist(list)\n    },\n    stat: () => {\n      if (!self.isOnline()) {\n        throw OFFLINE_ERROR\n      }\n\n      const stats = self._bitswap.stat()\n      stats.wantlist = formatWantlist(stats.wantlist)\n      stats.peers = stats.peers.map((id) => id.toB58String())\n\n      return stats\n    },\n    unwant: (key) => {\n      if (!self.isOnline()) {\n        throw OFFLINE_ERROR\n      }\n\n      // TODO: implement when https://github.com/ipfs/js-ipfs-bitswap/pull/10 is merged\n    }\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs/src/core/components/pubsub.js":"'use strict'\n\nconst promisify = require('promisify-es6')\nconst setImmediate = require('async/setImmediate')\n\nconst OFFLINE_ERROR = require('../utils').OFFLINE_ERROR\n\nmodule.exports = function pubsub (self) {\n  return {\n    subscribe: (topic, options, handler, callback) => {\n      if (!self.isOnline()) {\n        throw OFFLINE_ERROR\n      }\n\n      if (typeof options === 'function') {\n        callback = handler\n        handler = options\n        options = {}\n      }\n\n      if (!callback) {\n        return new Promise((resolve, reject) => {\n          subscribe(topic, options, handler, (err) => {\n            if (err) {\n              return reject(err)\n            }\n            resolve()\n          })\n        })\n      }\n\n      subscribe(topic, options, handler, callback)\n    },\n\n    unsubscribe: (topic, handler) => {\n      const ps = self._pubsub\n\n      ps.removeListener(topic, handler)\n\n      if (ps.listenerCount(topic) === 0) {\n        ps.unsubscribe(topic)\n      }\n    },\n\n    publish: promisify((topic, data, callback) => {\n      if (!self.isOnline()) {\n        return setImmediate(() => callback(OFFLINE_ERROR))\n      }\n\n      if (!Buffer.isBuffer(data)) {\n        return setImmediate(() => callback(new Error('data must be a Buffer')))\n      }\n\n      self._pubsub.publish(topic, data)\n      setImmediate(() => callback())\n    }),\n\n    ls: promisify((callback) => {\n      if (!self.isOnline()) {\n        return setImmediate(() => callback(OFFLINE_ERROR))\n      }\n\n      const subscriptions = Array.from(\n        self._pubsub.subscriptions\n      )\n\n      setImmediate(() => callback(null, subscriptions))\n    }),\n\n    peers: promisify((topic, callback) => {\n      if (!self.isOnline()) {\n        return setImmediate(() => callback(OFFLINE_ERROR))\n      }\n\n      const peers = Array.from(self._pubsub.peers.values())\n          .filter((peer) => peer.topics.has(topic))\n          .map((peer) => peer.info.id.toB58String())\n\n      setImmediate(() => callback(null, peers))\n    }),\n\n    setMaxListeners (n) {\n      return self._pubsub.setMaxListeners(n)\n    }\n  }\n\n  function subscribe (topic, options, handler, callback) {\n    const ps = self._pubsub\n\n    if (ps.listenerCount(topic) === 0) {\n      ps.subscribe(topic)\n    }\n\n    ps.on(topic, handler)\n    setImmediate(() => callback())\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs/.aegir.js":"'use strict'\n\nmodule.exports = {\n  karma: {\n    files: [{\n      pattern: 'node_modules/interface-ipfs-core/test/fixtures/**/*',\n      watched: false,\n      served: true,\n      included: false\n    }]\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs/gulpfile.js":"'use strict'\n\nconst gulp = require('gulp')\nconst parallel = require('async/parallel')\nconst series = require('async/series')\nconst createTempRepo = require('./test/utils/create-repo-node.js')\nconst HTTPAPI = require('./src/http-api')\nconst leftPad = require('left-pad')\n\nlet nodes = []\n\n/*\n * spawns a daemon with ports numbers starting in 10 and ending in `num`\n */\nfunction spawnDaemon (num, callback) {\n  num = leftPad(num, 3, 0)\n\n  const config = {\n    Addresses: {\n      Swarm: [\n        `/ip4/127.0.0.1/tcp/10${num}`,\n        `/ip4/127.0.0.1/tcp/20${num}/ws`\n      ],\n      API: `/ip4/127.0.0.1/tcp/31${num}`,\n      Gateway: `/ip4/127.0.0.1/tcp/32${num}`\n    },\n    Bootstrap: [],\n    Discovery: {\n      MDNS: {\n        Enabled: false\n      }\n    }\n  }\n\n  const daemon = new HTTPAPI(createTempRepo(), config)\n  nodes.push(daemon)\n  daemon.start(true, callback)\n}\n\ngulp.task('libnode:start', (done) => {\n  nodes = []\n  parallel([\n    (cb) => spawnDaemon(7, cb),\n    (cb) => spawnDaemon(8, cb),\n    (cb) => spawnDaemon(12, cb),\n    (cb) => spawnDaemon(13, cb)\n  ], done)\n})\n\ngulp.task('libnode:stop', (done) => {\n  series(nodes.map((node) => (cb) => {\n    setTimeout(() => node.stop(cb), 100)\n  }), done)\n})\n\ngulp.task('test:browser:before', ['libnode:start'])\ngulp.task('test:node:before', ['libnode:start'])\ngulp.task('test:browser:after', ['libnode:stop'])\ngulp.task('test:node:after', ['libnode:stop'])\n\nrequire('aegir/gulp')(gulp)\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs/src/index.js":"'use strict'\n\nconst IPFS = require('./core')\n\nexports = module.exports = IPFS\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs/src/cli/bin.js":"#! /usr/bin/env node\n\n'use strict'\n\nconst yargs = require('yargs')\nconst updateNotifier = require('update-notifier')\nconst readPkgUp = require('read-pkg-up')\nconst utils = require('./utils')\n\nconst pkg = readPkgUp.sync({cwd: __dirname}).pkg\nupdateNotifier({\n  pkg,\n  updateCheckInterval: 1000 * 60 * 60 * 24 * 7 // 1 week\n}).notify()\n\nconst cli = yargs\n  .commandDir('commands')\n  .demandCommand(1)\n\n// NOTE: This creates an alias of\n// `jsipfs files {add, get, cat}` to `jsipfs {add, get, cat}`.\n// This will stay until https://github.com/ipfs/specs/issues/98 is resolved.\nconst addCmd = require('./commands/files/add')\nconst catCmd = require('./commands/files/cat')\nconst getCmd = require('./commands/files/get')\nconst aliases = [addCmd, catCmd, getCmd]\naliases.forEach((alias) => {\n  cli.command(alias.command, alias.describe, alias.builder, alias.handler)\n})\n\nconst args = process.argv.slice(2)\n\n// Need to skip to avoid locking as these commands\n// don't require a daemon\nif (args[0] === 'daemon' || args[0] === 'init') {\n  return cli\n    .help()\n    .strict(false)\n    .completion()\n    .parse(args)\n}\n\nutils.getIPFS((err, ipfs, cleanup) => {\n  if (err) {\n    throw err\n  }\n\n  // finalize cli setup\n  cli // eslint-disable-line\n    .help()\n    .strict(false)\n    .completion()\n    .parse(args, {\n      ipfs: ipfs\n    }, (err, argv, output) => {\n      cleanup(() => {\n        if (err) {\n          throw err\n        }\n      })\n    })\n})\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs/src/cli/utils.js":"'use strict'\n\nconst fs = require('fs')\nconst os = require('os')\nconst APIctl = require('ipfs-api')\nconst multiaddr = require('multiaddr')\nconst IPFS = require('../core')\nconst path = require('path')\nconst debug = require('debug')\nconst log = debug('cli')\nlog.error = debug('cli:error')\n\nexports = module.exports\n\nexports.isDaemonOn = isDaemonOn\nfunction isDaemonOn () {\n  try {\n    fs.readFileSync(path.join(exports.getRepoPath(), 'api'))\n    log('daemon is on')\n    return true\n  } catch (err) {\n    log('daemon is off')\n    return false\n  }\n}\n\nexports.getAPICtl = getAPICtl\nfunction getAPICtl () {\n  if (!isDaemonOn()) {\n    throw new Error('daemon is not on')\n  }\n  const apiPath = path.join(exports.getRepoPath(), 'api')\n  const apiAddr = multiaddr(fs.readFileSync(apiPath).toString())\n  return APIctl(apiAddr.toString())\n}\n\nexports.getIPFS = (callback) => {\n  if (isDaemonOn()) {\n    return callback(null, getAPICtl(), (cb) => cb())\n  }\n\n  const node = new IPFS({\n    repo: exports.getRepoPath(),\n    init: false,\n    start: false,\n    EXPERIMENTAL: {\n      pubsub: true\n    }\n  })\n\n  const cleanup = (cb) => {\n    if (node && node._repo && !node._repo.closed) {\n      node._repo.close(() => cb())\n    } else {\n      cb()\n    }\n  }\n\n  node.on('error', (err) => {\n    throw err\n  })\n\n  node.once('ready', () => {\n    callback(null, node, cleanup)\n  })\n}\n\nexports.getRepoPath = () => {\n  return process.env.IPFS_PATH || os.homedir() + '/.jsipfs'\n}\n\nexports.createLogger = (visible) => {\n  return (msg, newline) => {\n    if (newline === undefined) {\n      newline = true\n    }\n    if (visible) {\n      if (msg === undefined) {\n        msg = ''\n      }\n      msg = newline ? msg + '\\n' : msg\n      process.stdout.write(msg)\n    }\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs-api/src/index.js":"'use strict'\n\nconst multiaddr = require('multiaddr')\nconst loadCommands = require('./load-commands')\nconst getConfig = require('./default-config')\nconst getRequestAPI = require('./request-api')\n\nfunction IpfsAPI (hostOrMultiaddr, port, opts) {\n  const config = getConfig()\n\n  try {\n    const maddr = multiaddr(hostOrMultiaddr).nodeAddress()\n    config.host = maddr.address\n    config.port = maddr.port\n  } catch (e) {\n    if (typeof hostOrMultiaddr === 'string') {\n      config.host = hostOrMultiaddr\n      config.port = port && typeof port !== 'object' ? port : config.port\n    }\n  }\n\n  let lastIndex = arguments.length\n  while (!opts && lastIndex-- > 0) {\n    opts = arguments[lastIndex]\n    if (opts) break\n  }\n\n  Object.assign(config, opts)\n\n  // autoconfigure in browser\n  if (!config.host &&\n    typeof self !== 'undefined') {\n    const split = self.location.host.split(':')\n    config.host = split[0]\n    config.port = split[1]\n  }\n\n  const requestAPI = getRequestAPI(config)\n  const cmds = loadCommands(requestAPI)\n  cmds.send = requestAPI\n  cmds.Buffer = Buffer\n\n  return cmds\n}\n\nexports = module.exports = IpfsAPI\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs-api/src/load-commands.js":"'use strict'\n\nfunction requireCommands () {\n  const cmds = {\n    // add and createAddStream alias\n    add: require('./api/add'),\n    cat: require('./api/cat'),\n    createAddStream: require('./api/create-add-stream'),\n    bitswap: require('./api/bitswap'),\n    block: require('./api/block'),\n    bootstrap: require('./api/bootstrap'),\n    commands: require('./api/commands'),\n    config: require('./api/config'),\n    dht: require('./api/dht'),\n    diag: require('./api/diag'),\n    id: require('./api/id'),\n    get: require('./api/get'),\n    log: require('./api/log'),\n    ls: require('./api/ls'),\n    mount: require('./api/mount'),\n    name: require('./api/name'),\n    object: require('./api/object'),\n    pin: require('./api/pin'),\n    ping: require('./api/ping'),\n    refs: require('./api/refs'),\n    repo: require('./api/repo'),\n    swarm: require('./api/swarm'),\n    update: require('./api/update'),\n    version: require('./api/version')\n  }\n\n  // TODO: crowding the 'files' namespace temporarily for interface-ipfs-core\n  // compatibility, until 'files vs mfs' naming decision is resolved.\n  cmds.files = function (send) {\n    const files = require('./api/files')(send)\n    files.add = require('./api/add')(send)\n    files.createAddStream = require('./api/create-add-stream.js')(send)\n    files.get = require('./api/get')(send)\n    files.cat = require('./api/cat')(send)\n\n    return files\n  }\n\n  cmds.util = function (send) {\n    const util = {\n      addFromFs: require('./api/util/fs-add')(send),\n      addFromStream: require('./api/add')(send),\n      addFromURL: require('./api/util/url-add')(send)\n    }\n    return util\n  }\n\n  return cmds\n}\n\nfunction loadCommands (send) {\n  const files = requireCommands()\n  const cmds = {}\n\n  Object.keys(files).forEach((file) => {\n    cmds[file] = files[file](send)\n  })\n\n  return cmds\n}\n\nmodule.exports = loadCommands\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs-api/src/default-config.js":"'use strict'\n\nconst pkg = require('../package.json')\n\nexports = module.exports = () => {\n  return {\n    'api-path': '/api/v0/',\n    'user-agent': `/node-${pkg.name}/${pkg.version}/`,\n    host: 'localhost',\n    port: '5001',\n    protocol: 'http'\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs-api/src/request-api.js":"'use strict'\n\nconst Qs = require('qs')\nconst isNode = require('detect-node')\nconst ndjson = require('ndjson')\nconst pump = require('pump')\nconst once = require('once')\nconst getFilesStream = require('./get-files-stream')\nconst streamToValue = require('./stream-to-value')\nconst streamToJsonValue = require('./stream-to-json-value')\nconst request = require('./request')\n\n// -- Internal\n\nfunction parseError (res, cb) {\n  const error = new Error(`Server responded with ${res.statusCode}`)\n  streamToJsonValue(res, (err, payload) => {\n    if (err) {\n      return cb(err)\n    }\n\n    if (payload) {\n      error.code = payload.Code\n      error.message = payload.Message || payload.toString()\n    }\n    cb(error)\n  })\n}\n\nfunction onRes (buffer, cb) {\n  return (res) => {\n    const stream = Boolean(res.headers['x-stream-output'])\n    const chunkedObjects = Boolean(res.headers['x-chunked-output'])\n    const isJson = res.headers['content-type'] &&\n                   res.headers['content-type'].indexOf('application/json') === 0\n\n    if (res.statusCode >= 400 || !res.statusCode) {\n      return parseError(res, cb)\n    }\n\n    // Return the response stream directly\n    if (stream && !buffer) {\n      return cb(null, res)\n    }\n\n    // Return a stream of JSON objects\n    if (chunkedObjects && isJson) {\n      const outputStream = pump(res, ndjson.parse())\n      return cb(null, outputStream)\n    }\n\n    // Return a JSON object\n    if (isJson) {\n      return streamToJsonValue(res, cb)\n    }\n\n    // Return a value\n    return streamToValue(res, cb)\n  }\n}\n\nfunction requestAPI (config, options, callback) {\n  options.qs = options.qs || {}\n  callback = once(callback)\n\n  if (Array.isArray(options.files)) {\n    options.qs.recursive = true\n  }\n\n  if (Array.isArray(options.path)) {\n    options.path = options.path.join('/')\n  }\n  if (options.args && !Array.isArray(options.args)) {\n    options.args = [options.args]\n  }\n  if (options.args) {\n    options.qs.arg = options.args\n  }\n  if (options.files && !Array.isArray(options.files)) {\n    options.files = [options.files]\n  }\n\n  if (options.qs.r) {\n    options.qs.recursive = options.qs.r\n    // From IPFS 0.4.0, it throws an error when both r and recursive are passed\n    delete options.qs.r\n  }\n\n  options.qs['stream-channels'] = true\n\n  let stream\n  if (options.files) {\n    stream = getFilesStream(options.files, options.qs)\n  }\n\n  // this option is only used internally, not passed to daemon\n  delete options.qs.followSymlinks\n\n  const method = 'POST'\n  const headers = {}\n\n  if (isNode) {\n    // Browsers do not allow you to modify the user agent\n    headers['User-Agent'] = config['user-agent']\n  }\n\n  if (options.files) {\n    if (!stream.boundary) {\n      return callback(new Error('No boundary in multipart stream'))\n    }\n\n    headers['Content-Type'] = `multipart/form-data; boundary=${stream.boundary}`\n  }\n\n  const qs = Qs.stringify(options.qs, {arrayFormat: 'repeat'})\n  const req = request(config.protocol)({\n    hostname: config.host,\n    path: `${config['api-path']}${options.path}?${qs}`,\n    port: config.port,\n    method: method,\n    headers: headers\n  }, onRes(options.buffer, callback))\n\n  req.on('error', (err) => {\n    callback(err)\n  })\n\n  if (options.files) {\n    stream.pipe(req)\n  } else {\n    req.end()\n  }\n\n  return req\n}\n\n//\n// -- Module Interface\n\nexports = module.exports = (config) => {\n  /*\n   * options: {\n   *   path:   // API path (like /add or /config) - type: string\n   *   args:   // Arguments to the command - type: object\n   *   qs:     // Opts as query string opts to the command --something - type: object\n   *   files:  // files to be sent - type: string, buffer or array of strings or buffers\n   *   buffer: // buffer the request before sending it - type: bool\n   * }\n   */\n  const send = (options, callback) => {\n    if (typeof options !== 'object') {\n      return callback(new Error('no options were passed'))\n    }\n\n    return requestAPI(config, options, callback)\n  }\n\n  // Send a HTTP request and pass via a transform function\n  // to convert the response data to wanted format before\n  // returning it to the callback.\n  // Eg. send.andTransform({}, (e) => JSON.parse(e), (err, res) => ...)\n  send.andTransform = (options, transform, callback) => {\n    return send(options, (err, res) => {\n      if (err) {\n        return callback(err)\n      }\n      transform(res, callback)\n    })\n  }\n\n  return send\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs-api/src/get-files-stream.js":"'use strict'\n\nconst isNode = require('detect-node')\nconst Multipart = require('multipart-stream')\nconst flatmap = require('flatmap')\nconst escape = require('glob-escape')\n\nfunction headers (file) {\n  const name = file.path || ''\n  const header = {\n    'Content-Disposition': `file; filename=\"${name}\"`\n  }\n\n  if (file.dir || !file.content) {\n    header['Content-Type'] = 'application/x-directory'\n  } else if (file.symlink) {\n    header['Content-Type'] = 'application/symlink'\n  } else {\n    header['Content-Type'] = 'application/octet-stream'\n  }\n\n  return header\n}\n\nfunction strip (name, base) {\n  const smallBase = base\n        .split('/')\n        .slice(0, -1)\n        .join('/') + '/'\n  return name.replace(smallBase, '')\n}\n\nfunction loadPaths (opts, file) {\n  const path = require('path')\n  const fs = require('fs')\n  const glob = require('glob')\n\n  const followSymlinks = opts.followSymlinks != null ? opts.followSymlinks : true\n\n  file = path.resolve(file)\n  const stats = fs.statSync(file)\n\n  if (stats.isDirectory() && !opts.recursive) {\n    throw new Error('Can only add directories using --recursive')\n  }\n\n  if (stats.isDirectory() && opts.recursive) {\n    const globEscapedDir = escape(file) + (file.endsWith('/') ? '' : '/')\n    const mg = new glob.sync.GlobSync(`${globEscapedDir}` + '**/*', {\n      follow: followSymlinks,\n      dot: opts.hidden,\n      ignore: (opts.ignore || []).map(function (ignoreGlob) {\n        return globEscapedDir + ignoreGlob\n      })\n    })\n\n    return mg.found\n      .map((name) => {\n        // symlinks\n        if (mg.symlinks[name] === true) {\n          return {\n            path: strip(name, file),\n            symlink: true,\n            dir: false,\n            content: fs.readlinkSync(name)\n          }\n        }\n\n        // files\n        if (mg.cache[name] === 'FILE') {\n          return {\n            path: strip(name, file),\n            symlink: false,\n            dir: false,\n            content: fs.createReadStream(name)\n          }\n        }\n\n        // directories\n        if (mg.cache[name] === 'DIR' || mg.cache[name] instanceof Array) {\n          return {\n            path: strip(name, file),\n            symlink: false,\n            dir: true\n          }\n        }\n        // files inside symlinks and others\n      })\n      // filter out null files\n      .filter(Boolean)\n  }\n\n  return {\n    path: path.basename(file),\n    content: fs.createReadStream(file)\n  }\n}\n\nfunction getFilesStream (files, opts) {\n  if (!files) {\n    return null\n  }\n\n  const mp = new Multipart()\n\n  flatmap(files, (file) => {\n    if (typeof file === 'string') {\n      if (!isNode) {\n        throw new Error('Can not add paths in node')\n      }\n\n      return loadPaths(opts, file)\n    }\n\n    if (file.path && !file.content) {\n      file.dir = true\n      return file\n    }\n\n    if (file.path && (file.content || file.dir)) {\n      return file\n    }\n\n    return {\n      path: '',\n      symlink: false,\n      dir: false,\n      content: file\n    }\n  }).forEach((file) => {\n    mp.addPart({\n      headers: headers(file),\n      body: file.content\n    })\n  })\n\n  return mp\n}\n\nexports = module.exports = getFilesStream\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs-api/src/stream-to-value.js":"'use strict'\n\nconst pump = require('pump')\nconst concat = require('concat-stream')\n\n/*\n  Concatenate a stream to a single value.\n*/\nfunction streamToValue (res, callback) {\n  const done = (data) => callback(null, data)\n  pump(res, concat(done), (err) => {\n    if (err) callback(err)\n  })\n}\n\nmodule.exports = streamToValue\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs-api/src/stream-to-json-value.js":"'use strict'\n\nconst streamToValue = require('./stream-to-value')\n\n/*\n  Converts a stream to a single JSON value\n*/\nfunction streamToJsonValue (res, cb) {\n  streamToValue(res, (err, data) => {\n    if (err) {\n      return cb(err)\n    }\n\n    if (!data || data.length === 0) {\n      return cb()\n    }\n\n    // TODO: check if needed, afaik JSON.parse can parse Buffers\n    if (Buffer.isBuffer(data)) {\n      data = data.toString()\n    }\n\n    let res\n    try {\n      res = JSON.parse(data)\n    } catch (err) {\n      return cb(err)\n    }\n\n    cb(null, res)\n  })\n}\n\nmodule.exports = streamToJsonValue\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs-api/src/request.js":"'use strict'\n\nconst httpRequest = require('http').request\nconst httpsRequest = require('https').request\n\nmodule.exports = (protocol) => {\n  if (protocol.indexOf('https') === 0) {\n    return httpsRequest\n  }\n\n  return httpRequest\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs/src/core/default-repo-browser.js":"'use strict'\n\nconst IPFSRepo = require('ipfs-repo')\n\nmodule.exports = (dir) => {\n  const repoPath = dir || 'ipfs'\n  return new IPFSRepo(repoPath)\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs/src/core/state.js":"'use strict'\n\nconst debug = require('debug')\nconst log = debug('jsipfs:state')\nlog.error = debug('jsipfs:state:error')\n\nconst fsm = require('fsm-event')\n\nmodule.exports = (self) => {\n  const s = fsm('uninitalized', {\n    uninitalized: {\n      init: 'initializing',\n      initialized: 'stopped'\n    },\n    initializing: {\n      initialized: 'stopped'\n    },\n    stopped: {\n      start: 'starting'\n    },\n    starting: {\n      started: 'running'\n    },\n    running: {\n      stop: 'stopping'\n    },\n    stopping: {\n      stopped: 'stopped'\n    }\n  })\n\n  // log events\n  s.on('error', (err) => log.error(err))\n  s.on('done', () => log('-> ' + s._state))\n\n  // -- Actions\n\n  s.init = () => {\n    s('init')\n  }\n\n  s.initialized = () => {\n    s('initialized')\n  }\n\n  s.stop = () => {\n    s('stop')\n  }\n\n  s.stopped = () => {\n    s('stopped')\n  }\n\n  s.start = () => {\n    s('start')\n  }\n\n  s.started = () => {\n    s('started')\n  }\n\n  s.state = () => s._state\n\n  return s\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs/src/http-api/error-handler.js":"'use strict'\n\nconst Hoek = require('hoek')\n\nmodule.exports = (api, server) => {\n  server.ext('onRequest', (request, reply) => {\n    request.handleError = handleError\n    reply.continue()\n  })\n\n  server.ext('onPreResponse', (request, reply) => {\n    const res = request.response\n    const req = request.raw.req\n\n    let statusCode = 200\n    let msg = 'Sorry, something went wrong, please retrace your steps.'\n\n    if (res.isBoom) {\n      statusCode = res.output.payload.statusCode\n\n      if (res.message && res.isDeveloperError) {\n        msg = res.message.replace('Uncaught error: ', '')\n      }\n\n      const debug = {\n        method: req.method,\n        url: request.url.path,\n        headers: request.raw.req.headers,\n        info: request.info,\n        payload: request.payload,\n        response: res.output.payload\n      }\n\n      api.log.error(res.stack)\n      server.log('error', debug)\n\n      reply({\n        Message: msg,\n        Code: 1\n      }).code(statusCode)\n      return\n    }\n\n    reply.continue()\n  })\n}\n\nfunction handleError (error, errorMessage) {\n  if (errorMessage) {\n    return Hoek.assert(!error, errorMessage)\n  }\n\n  return Hoek.assert(!error, error)\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs/src/cli/commands/bitswap.js":"'use strict'\n\nmodule.exports = {\n  command: 'bitswap',\n\n  description: 'A set of commands to manipulate the bitswap agent.',\n\n  builder (yargs) {\n    return yargs\n      .commandDir('bitswap')\n  },\n\n  handler (argv) {\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs/src/cli/commands/block.js":"'use strict'\n\nmodule.exports = {\n  command: 'block',\n\n  description: 'Manipulate raw IPFS blocks.',\n\n  builder (yargs) {\n    return yargs\n      .commandDir('block')\n  },\n\n  handler (argv) {\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs/src/cli/commands/bootstrap.js":"'use strict'\n\nmodule.exports = {\n  command: 'bootstrap',\n\n  description: 'Show or edit the list of bootstrap peers.',\n\n  builder (yargs) {\n    return yargs\n      .commandDir('bootstrap')\n  },\n\n  handler (argv) {\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs/src/cli/commands/commands.js":"'use strict'\n\nconst path = require('path')\nconst glob = require('glob').sync\n\nmodule.exports = {\n  command: 'commands',\n\n  describe: 'List all available commands',\n\n  handler () {\n    const basePath = path.resolve(__dirname, '..')\n\n    // modeled after https://github.com/vdemedes/ronin/blob/master/lib/program.js#L78\n    const files = glob(path.join(basePath, 'commands', '**', '*.js'))\n    const cmds = files.map((p) => {\n      return p.replace(/\\//g, path.sep)\n        .replace(/^./, ($1) => $1.toUpperCase())\n        .replace(path.join(basePath, 'commands'), '')\n        .replace(path.sep, '')\n        .split(path.sep)\n        .join(' ')\n        .replace('.js', '')\n    }).sort().map((cmd) => `ipfs ${cmd}`)\n\n    console.log(['ipfs'].concat(cmds).join('\\n'))\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs/src/cli/commands/config.js":"'use strict'\n\nmodule.exports = {\n  command: 'config <key> [value]',\n\n  description: 'Get and set IPFS config values',\n\n  builder (yargs) {\n    return yargs\n      .commandDir('config')\n      .options({\n        bool: {\n          type: 'boolean',\n          default: false,\n          global: false\n        },\n        json: {\n          type: 'boolean',\n          default: false,\n          global: false\n        }\n      })\n  },\n\n  handler (argv) {\n    if (argv._handled) {\n      return\n    }\n    argv._handled = true\n\n    const bool = argv.bool\n    const json = argv.json\n    const key = argv.key\n    let value = argv.value\n\n    if (!value) {\n      // Get the value of a given key\n      argv.ipfs.config.get(key, (err, value) => {\n        if (err) {\n          throw new Error('failed to read the config')\n        }\n\n        if (typeof value === 'object') {\n          console.log(JSON.stringify(value, null, 2))\n        } else {\n          console.log(value)\n        }\n      })\n    } else {\n      // Set the new value of a given key\n\n      if (bool) {\n        value = (value === 'true')\n      } else if (json) {\n        try {\n          value = JSON.parse(value)\n        } catch (err) {\n          throw new Error('invalid JSON provided')\n        }\n      }\n\n      argv.ipfs.config.set(key, value, (err) => {\n        if (err) {\n          throw new Error('failed to read the config')\n        }\n      })\n    }\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs/src/cli/commands/daemon.js":"'use strict'\n\nconst HttpAPI = require('../../http-api')\nconst utils = require('../utils')\n\nlet httpAPI\n\nmodule.exports = {\n  command: 'daemon',\n\n  describe: 'Start a long-running daemon process',\n\n  handler () {\n    console.log('Initializing daemon...')\n\n    const repoPath = utils.getRepoPath()\n    httpAPI = new HttpAPI(repoPath)\n\n    httpAPI.start((err) => {\n      if (err && err.code === 'ENOENT') {\n        console.log('Error: no ipfs repo found in ' + repoPath)\n        console.log('please run: jsipfs init')\n        process.exit(1)\n      }\n      if (err) {\n        throw err\n      }\n      console.log('Daemon is ready')\n    })\n\n    process.on('SIGINT', () => {\n      console.log('Received interrupt signal, shutting down..')\n      httpAPI.stop((err) => {\n        if (err) {\n          throw err\n        }\n        process.exit(0)\n      })\n    })\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs/src/http-api/index.js":"'use strict'\n\nconst series = require('async/series')\nconst Hapi = require('hapi')\nconst debug = require('debug')\nconst multiaddr = require('multiaddr')\nconst setHeader = require('hapi-set-header')\nconst once = require('once')\n\nconst IPFS = require('../core')\nconst errorHandler = require('./error-handler')\n\nfunction uriToMultiaddr (uri) {\n  const ipPort = uri.split('/')[2].split(':')\n  return `/ip4/${ipPort[0]}/tcp/${ipPort[1]}`\n}\n\nfunction HttpApi (repo, config) {\n  this.node = undefined\n  this.server = undefined\n\n  this.log = debug('jsipfs:http-api')\n  this.log.error = debug('jsipfs:http-api:error')\n\n  this.start = (init, callback) => {\n    if (typeof init === 'function') {\n      callback = init\n      init = false\n    }\n    this.log('starting')\n\n    series([\n      (cb) => {\n        // try-catch so that programmer errors are not swallowed during testing\n        try {\n          // start the daemon\n          this.node = new IPFS({\n            repo: repo,\n            init: init,\n            start: true,\n            config: config,\n            EXPERIMENTAL: {\n              pubsub: true\n            }\n          })\n        } catch (err) {\n          return cb(err)\n        }\n\n        cb = once(cb)\n\n        this.node.once('error', (err) => {\n          this.log('error starting core', err)\n          err.code = 'ENOENT'\n          cb(err)\n        })\n        this.node.once('start', cb)\n      },\n      (cb) => {\n        this.log('fetching config')\n        this.node._repo.config.get((err, config) => {\n          if (err) {\n            return callback(err)\n          }\n\n          // CORS is enabled by default\n          this.server = new Hapi.Server({\n            connections: { routes: { cors: true } }\n          })\n\n          this.server.app.ipfs = this.node\n          const api = config.Addresses.API.split('/')\n          const gateway = config.Addresses.Gateway.split('/')\n\n          // select which connection with server.select(<label>) to add routes\n          this.server.connection({\n            host: api[2],\n            port: api[4],\n            labels: 'API'\n          })\n\n          this.server.connection({\n            host: gateway[2],\n            port: gateway[4],\n            labels: 'Gateway'\n          })\n\n          // Nicer errors\n          errorHandler(this, this.server)\n\n          // load routes\n          require('./routes')(this.server)\n\n          // Set default headers\n          setHeader(this.server,\n            'Access-Control-Allow-Headers',\n            'X-Stream-Output, X-Chunked-Output, X-Content-Length')\n          setHeader(this.server,\n            'Access-Control-Expose-Headers',\n            'X-Stream-Output, X-Chunked-Output, X-Content-Length')\n\n          this.server.start(cb)\n        })\n      },\n      (cb) => {\n        const api = this.server.select('API')\n        const gateway = this.server.select('Gateway')\n        this.apiMultiaddr = multiaddr('/ip4/127.0.0.1/tcp/' + api.info.port)\n        api.info.ma = uriToMultiaddr(api.info.uri)\n        gateway.info.ma = uriToMultiaddr(gateway.info.uri)\n\n        console.log('API is listening on: %s', api.info.ma)\n        console.log('Gateway (readonly) is listening on: %s', gateway.info.ma)\n\n        // for the CLI to know the where abouts of the API\n        this.node._repo.setApiAddress(api.info.ma, cb)\n      }\n    ], (err) => {\n      this.log('done', err)\n      callback(err)\n    })\n  }\n\n  this.stop = (callback) => {\n    this.log('stopping')\n    series([\n      (cb) => this.server.stop(cb),\n      (cb) => this.node.stop(cb)\n    ], (err) => {\n      if (err) {\n        this.log.error(err)\n        console.log('There were errors stopping')\n      }\n      callback()\n    })\n  }\n}\n\nmodule.exports = HttpApi\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs/src/cli/commands/dag.js":"'use strict'\n\nmodule.exports = {\n  command: 'dag',\n\n  description: 'Interact with ipld dag objects.',\n\n  builder (yargs) {\n    return yargs\n      .commandDir('dag')\n  },\n\n  handler (argv) {\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs/src/cli/commands/dns.js":"'use strict'\n\nmodule.exports = {\n  command: 'dns',\n\n  describe: '',\n\n  handler (argv) {\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs/src/cli/commands/files.js":"'use strict'\n\nmodule.exports = {\n  command: 'files',\n\n  description: 'Unixfs commands',\n\n  builder (yargs) {\n    return yargs\n      .commandDir('files')\n  },\n\n  handler (argv) {}\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs/src/cli/commands/id.js":"'use strict'\n\nmodule.exports = {\n  command: 'id',\n\n  describe: 'Shows IPFS Node ID info',\n\n  builder: {\n    format: {\n      alias: 'f',\n      type: 'string'\n    }\n  },\n\n  handler (argv) {\n    // TODO: handle argv.format\n    argv.ipfs.id((err, id) => {\n      if (err) {\n        throw err\n      }\n\n      console.log(JSON.stringify(id, '', 2))\n    })\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs/src/cli/commands/init.js":"'use strict'\n\nconst Repo = require('ipfs-repo')\nconst IPFS = require('../../core')\nconst utils = require('../utils')\n\nmodule.exports = {\n  command: 'init',\n\n  describe: 'Initialize a local IPFS node',\n\n  builder: {\n    bits: {\n      type: 'number',\n      alias: 'b',\n      default: '2048',\n      describe: 'Number of bits to use in the generated RSA private key (defaults to 2048)'\n    },\n    emptyRepo: {\n      alias: 'e',\n      type: 'boolean',\n      describe: \"Don't add and pin help files to the local storage\"\n    }\n  },\n\n  handler (argv) {\n    const path = utils.getRepoPath()\n\n    const log = utils.createLogger(true)\n    log(`initializing ipfs node at ${path}`)\n\n    const node = new IPFS({\n      repo: new Repo(path),\n      init: false,\n      start: false\n    })\n\n    node.init({\n      bits: argv.bits,\n      emptyRepo: argv.emptyRepo,\n      log: log\n    }, (err) => {\n      if (err) {\n        if (err.code === 'EACCES') {\n          err.message = `EACCES: permission denied, stat $IPFS_PATH/version`\n        }\n        console.error(err.toString())\n        process.exit(1)\n      }\n    })\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs/src/cli/commands/ls.js":"'use strict'\n\nmodule.exports = {\n  command: 'ls',\n\n  describe: '',\n\n  handler (argv) {\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs/src/cli/commands/mount.js":"'use strict'\n\nmodule.exports = {\n  command: 'mount',\n\n  describe: '',\n\n  handler (argv) {\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs/src/cli/commands/object.js":"'use strict'\n\nmodule.exports = {\n  command: 'object',\n\n  description: 'Interact with ipfs objects.',\n\n  builder (yargs) {\n    return yargs\n      .commandDir('object')\n  },\n\n  handler (argv) {\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs/src/cli/commands/ping.js":"'use strict'\n\nmodule.exports = {\n  command: 'ping',\n\n  describe: '',\n\n  handler (argv) {\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs/src/cli/commands/pubsub.js":"'use strict'\n\nmodule.exports = {\n  command: 'pubsub',\n\n  description: 'pubsub commands',\n\n  builder (yargs) {\n    return yargs\n      .commandDir('pubsub')\n  },\n\n  handler (argv) {}\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs/src/cli/commands/refs.js":"'use strict'\n\nmodule.exports = {\n  command: 'refs',\n\n  describe: '',\n\n  handler (argv) {\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs/src/cli/commands/repo.js":"'use strict'\n\nmodule.exports = {\n  command: 'repo',\n\n  description: 'Manipulate the IPFS repo.',\n\n  builder (yargs) {\n    return yargs\n      .commandDir('repo')\n  },\n\n  handler (argv) {\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs/src/cli/commands/resolve.js":"'use strict'\n\nmodule.exports = {\n  command: 'resolve',\n\n  describe: '',\n\n  handler (argv) {\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs/src/cli/commands/swarm.js":"'use strict'\n\nmodule.exports = {\n  command: 'swarm',\n\n  description: 'Swarm inspection tool.',\n\n  builder (yargs) {\n    return yargs\n      .commandDir('swarm')\n  },\n\n  handler (argv) {\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs/src/cli/commands/update.js":"'use strict'\n\nmodule.exports = {\n  command: 'update',\n\n  describe: '',\n\n  handler (argv) {\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-ipfs/node_modules/ipfs/src/cli/commands/version.js":"'use strict'\n\nmodule.exports = {\n  command: 'version',\n\n  describe: 'Shows IPFS version information',\n\n  builder: {\n    number: {\n      alias: 'n',\n      type: 'boolean',\n      default: false\n    },\n    commit: {\n      type: 'boolean',\n      default: false\n    },\n    repo: {\n      type: 'boolean',\n      default: false\n    }\n  },\n\n  handler (argv) {\n    // TODO: handle argv.{repo|commit|number}\n    argv.ipfs.version((err, version) => {\n      if (err) {\n        throw err\n      }\n\n      console.log(`js-ipfs version: ${version.version}`)\n    })\n  }\n}\n"}